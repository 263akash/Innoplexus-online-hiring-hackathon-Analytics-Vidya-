{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_data=pd.read_csv(\"\train_F3WbcTw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5279, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0</td>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eba8f80e7e20f3a2f48685530748fbfa95943e4</td>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe809672251f6bd0d986e00380f48d047c7e7b76</td>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>fingolimod</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bd22104dfa9ec80db4099523e03fae7a52735eb6</td>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>ocrevus</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b227688381f9b25e5b65109dd00f7f895e838249</td>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>gilenya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  \\\n",
       "0  2e180be4c9214c1f5ab51fd8cc32bc80c9f612e0   \n",
       "1  9eba8f80e7e20f3a2f48685530748fbfa95943e4   \n",
       "2  fe809672251f6bd0d986e00380f48d047c7e7b76   \n",
       "3  bd22104dfa9ec80db4099523e03fae7a52735eb6   \n",
       "4  b227688381f9b25e5b65109dd00f7f895e838249   \n",
       "\n",
       "                                                text        drug  sentiment  \n",
       "0  Autoimmune diseases tend to come in clusters. ...     gilenya          2  \n",
       "1  I can completely understand why you’d want to ...     gilenya          2  \n",
       "2  Interesting that it only targets S1P-1/5 recep...  fingolimod          2  \n",
       "3  Very interesting, grand merci. Now I wonder wh...     ocrevus          2  \n",
       "4  Hi everybody, My latest MRI results for Brain ...     gilenya          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5279, 4)\n",
      "unique_hash    0\n",
      "text           0\n",
      "drug           0\n",
      "sentiment      0\n",
      "dtype: int64\n",
      "5279 unique hash\n",
      "102  unique drugs\n",
      "2    3825\n",
      "1     837\n",
      "0     617\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (train_data.shape)\n",
    "print (train_data.isnull().sum())\n",
    "print (f\"{train_data.unique_hash.nunique()} unique hash\") #all unique_hash values are unique \n",
    "print (f\"{train_data.drug.nunique()}  unique drugs\")        #we have 102 unique drugs\n",
    "print (train_data.sentiment.value_counts()) #3 sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 3)\n",
      "unique_hash    0\n",
      "text           0\n",
      "drug           0\n",
      "dtype: int64\n",
      "2924\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "print (test_data.shape)\n",
    "print (test_data.isnull().sum())\n",
    "print (test_data.unique_hash.nunique()) #all unique_hash values are unique \n",
    "print (test_data.drug.nunique())        #we have 102 unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  drug  sentiment\n",
       "0  Autoimmune diseases tend to come in clusters. ...    38          2\n",
       "1  I can completely understand why you’d want to ...    38          2\n",
       "2  Interesting that it only targets S1P-1/5 recep...    35          2\n",
       "3  Very interesting, grand merci. Now I wonder wh...    64          2\n",
       "4  Hi everybody, My latest MRI results for Brain ...    38          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "train_data[\"drug\"]=label.fit_transform(train_data[\"drug\"])\n",
    "train_data.drop(\"unique_hash\",axis=1,inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "port=PorterStemmer()\n",
    "word_=WordNetLemmatizer()\n",
    "def lemmatize_stemming(text):\n",
    "    return port.stem(word_.lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    print (text)\n",
    "    for token in simple_preprocess(text):\n",
    "        print (token)\n",
    "        if token not in STOPWORDS and len(token)>3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    joined_words=\" \".join(result)\n",
    "    return joined_words\n",
    "\"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer,PorterStemmer\n",
    "import string\n",
    "def clean_text(text):\n",
    "    ## Remove puncuation\n",
    "    text = text.translate(string.punctuation)\n",
    "    ## Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "    ## Remove stop words\n",
    "    text = [w for w in text if not w in sw and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    ## Stemming\n",
    "    txt = text.split()\n",
    "    text = [i for i in txt if i.isalpha()]\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    text=text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=train_data[\"text\"][0]\n",
    "#print (x)\n",
    "#x=train_data[\"text\"][0].apply(preprocess)\n",
    "#preprocess(x)\n",
    "#x\n",
    "#descp=train_data[\"text\"].apply(preprocess)\n",
    "descp=train_data[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoimmune diseases tend to come in clusters. ...</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can completely understand why you’d want to ...</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interesting that it only targets S1P-1/5 recep...</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very interesting, grand merci. Now I wonder wh...</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi everybody, My latest MRI results for Brain ...</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  drug  sentiment\n",
       "0  Autoimmune diseases tend to come in clusters. ...    38          2\n",
       "1  I can completely understand why you’d want to ...    38          2\n",
       "2  Interesting that it only targets S1P-1/5 recep...    35          2\n",
       "3  Very interesting, grand merci. Now I wonder wh...    64          2\n",
       "4  Hi everybody, My latest MRI results for Brain ...    38          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data.to_csv(\"train_innoplexus.csv\")\n",
    "descp[0]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfvec=TfidfVectorizer(min_df=3, max_features=1000,strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(1, 4), use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "transvec=tfvec.fit_transform(descp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tsvd=TruncatedSVD(n_components=50)\n",
    "data_text=tsvd.fit_transform(transvec)\n",
    "new_data=pd.DataFrame(data_text,columns=[\"n\"+str(i) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>...</th>\n",
       "      <th>n40</th>\n",
       "      <th>n41</th>\n",
       "      <th>n42</th>\n",
       "      <th>n43</th>\n",
       "      <th>n44</th>\n",
       "      <th>n45</th>\n",
       "      <th>n46</th>\n",
       "      <th>n47</th>\n",
       "      <th>n48</th>\n",
       "      <th>n49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.292797</td>\n",
       "      <td>-0.210832</td>\n",
       "      <td>0.037319</td>\n",
       "      <td>-0.248554</td>\n",
       "      <td>-0.124324</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.215588</td>\n",
       "      <td>0.198353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.073548</td>\n",
       "      <td>0.015384</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>-0.093104</td>\n",
       "      <td>0.02066</td>\n",
       "      <td>-0.016259</td>\n",
       "      <td>0.058313</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>-0.012436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363099</td>\n",
       "      <td>-0.084139</td>\n",
       "      <td>-0.037395</td>\n",
       "      <td>-0.184300</td>\n",
       "      <td>-0.155908</td>\n",
       "      <td>0.030592</td>\n",
       "      <td>0.182617</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041814</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.049422</td>\n",
       "      <td>0.043905</td>\n",
       "      <td>0.039392</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>0.036370</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>0.057347</td>\n",
       "      <td>0.056890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug  sentiment        n0        n1        n2        n3        n4  \\\n",
       "0    38          2  0.292797 -0.210832  0.037319 -0.248554 -0.124324   \n",
       "1    38          2  0.363099 -0.084139 -0.037395 -0.184300 -0.155908   \n",
       "\n",
       "         n5        n6        n7    ...          n40       n41       n42  \\\n",
       "0 -0.006031  0.215588  0.198353    ...     0.033431  0.073548  0.015384   \n",
       "1  0.030592  0.182617  0.005156    ...     0.041814 -0.030149  0.049422   \n",
       "\n",
       "        n43       n44      n45       n46       n47       n48       n49  \n",
       "0  0.022584 -0.093104  0.02066 -0.016259  0.058313  0.011339 -0.012436  \n",
       "1  0.043905  0.039392  0.01003  0.036370  0.032603  0.057347  0.056890  \n",
       "\n",
       "[2 rows x 52 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod=pd.concat([train_data,new_data],axis=1)\n",
    "train_mod.drop(\"text\",axis=1,inplace=True)\n",
    "train_mod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5279, 51)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "train_mod.drop(\"sentiment\",axis=1,inplace=True)\n",
    "#scaled=train_mod.loc[:,train_mod.columns!=\"sentiment\"]\n",
    "scaled=sc.fit_transform(train_mod)\n",
    "print (scaled.shape)\n",
    "print (type(scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5279, 51)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>...</th>\n",
       "      <th>n40</th>\n",
       "      <th>n41</th>\n",
       "      <th>n42</th>\n",
       "      <th>n43</th>\n",
       "      <th>n44</th>\n",
       "      <th>n45</th>\n",
       "      <th>n46</th>\n",
       "      <th>n47</th>\n",
       "      <th>n48</th>\n",
       "      <th>n49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.648663</td>\n",
       "      <td>0.156338</td>\n",
       "      <td>-1.346728</td>\n",
       "      <td>0.303039</td>\n",
       "      <td>-2.168141</td>\n",
       "      <td>-1.416341</td>\n",
       "      <td>-0.150591</td>\n",
       "      <td>2.372560</td>\n",
       "      <td>2.333787</td>\n",
       "      <td>0.930002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648471</td>\n",
       "      <td>1.426587</td>\n",
       "      <td>0.287815</td>\n",
       "      <td>0.464816</td>\n",
       "      <td>-1.817205</td>\n",
       "      <td>0.421050</td>\n",
       "      <td>-0.346911</td>\n",
       "      <td>1.183177</td>\n",
       "      <td>0.225349</td>\n",
       "      <td>-0.253613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.648663</td>\n",
       "      <td>0.830113</td>\n",
       "      <td>-0.526050</td>\n",
       "      <td>-0.297917</td>\n",
       "      <td>-1.607420</td>\n",
       "      <td>-1.751460</td>\n",
       "      <td>0.240289</td>\n",
       "      <td>2.014315</td>\n",
       "      <td>0.049432</td>\n",
       "      <td>-0.343953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809820</td>\n",
       "      <td>-0.578225</td>\n",
       "      <td>0.952456</td>\n",
       "      <td>0.886292</td>\n",
       "      <td>0.807237</td>\n",
       "      <td>0.209942</td>\n",
       "      <td>0.703559</td>\n",
       "      <td>0.664646</td>\n",
       "      <td>1.158057</td>\n",
       "      <td>1.165381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       drug        n0        n1        n2        n3        n4        n5  \\\n",
       "0 -0.648663  0.156338 -1.346728  0.303039 -2.168141 -1.416341 -0.150591   \n",
       "1 -0.648663  0.830113 -0.526050 -0.297917 -1.607420 -1.751460  0.240289   \n",
       "\n",
       "         n6        n7        n8    ...          n40       n41       n42  \\\n",
       "0  2.372560  2.333787  0.930002    ...     0.648471  1.426587  0.287815   \n",
       "1  2.014315  0.049432 -0.343953    ...     0.809820 -0.578225  0.952456   \n",
       "\n",
       "        n43       n44       n45       n46       n47       n48       n49  \n",
       "0  0.464816 -1.817205  0.421050 -0.346911  1.183177  0.225349 -0.253613  \n",
       "1  0.886292  0.807237  0.209942  0.703559  0.664646  1.158057  1.165381  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_training_data=pd.DataFrame(data=scaled,columns=train_mod.columns)\n",
    "modified_training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_mod=train_mod.drop([\"unique_hash\"],axis=1)\n",
    "#train_mod.drop(\"unique_hash\",axis=1,inplace=True)\n",
    "from sklearn.utils import shuffle\n",
    "modified_training_data=shuffle(modified_training_data)\n",
    "\n",
    "#X=modified_training_data.loc[:,modified_training_data.columns!=\"sentiment\"]\n",
    "X=modified_training_data\n",
    "Y=train_data[\"sentiment\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738    2\n",
       "3771    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_training_data.head(2)\n",
    "y_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1738    2\n",
       "3771    1\n",
       "2634    2\n",
       "4199    2\n",
       "2694    0\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5618686868686869\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-6ff4d8bc548b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    718\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    719\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    835\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1045\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1047\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1048\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "pred=dt.predict(x_test)\n",
    "print (accuracy_score(y_test,pred))\n",
    "f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7234848484848485"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=500)\n",
    "rfc.fit(x_train,y_train)\n",
    "pred2=rfc.predict(x_test)\n",
    "accuracy_score(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7266414141414141"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv=SVC()\n",
    "sv.fit(x_train,y_train)\n",
    "pred3=sv.predict(x_test)\n",
    "accuracy_score(y_test,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266414141414141"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "rc=RidgeClassifier()\n",
    "rc.fit(x_train,y_train)\n",
    "pred4=rc.predict(x_test)\n",
    "accuracy_score(y_test,pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5997474747474747"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "pred5=sgd.predict(x_test)\n",
    "accuracy_score(y_test,pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266414141414141"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(multi_class='multinomial',C=1,solver='saga')\n",
    "lr.fit(x_train,y_train)\n",
    "pred6=lr.predict(x_test)\n",
    "accuracy_score(y_test,pred6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7178030303030303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate =0.04,n_estimators=2000,max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,scale_pos_weight=1,seed=27)\n",
    "\n",
    "xgb.fit(x_train,y_train)\n",
    "pred7 = xgb.predict(x_test)\n",
    "accuracy_score(y_test,pred7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: -1.0794456\ttotal: 1.04s\tremaining: 17m 22s\n",
      "1:\tlearn: -1.0616235\ttotal: 1.88s\tremaining: 15m 36s\n",
      "2:\tlearn: -1.0452161\ttotal: 2.7s\tremaining: 14m 56s\n",
      "3:\tlearn: -1.0296838\ttotal: 3.5s\tremaining: 14m 30s\n",
      "4:\tlearn: -1.0147875\ttotal: 4.23s\tremaining: 14m 2s\n",
      "5:\tlearn: -1.0009376\ttotal: 5.03s\tremaining: 13m 53s\n",
      "6:\tlearn: -0.9880323\ttotal: 5.83s\tremaining: 13m 46s\n",
      "7:\tlearn: -0.9759032\ttotal: 6.61s\tremaining: 13m 39s\n",
      "8:\tlearn: -0.9641873\ttotal: 7.32s\tremaining: 13m 25s\n",
      "9:\tlearn: -0.9535195\ttotal: 8.11s\tremaining: 13m 23s\n",
      "10:\tlearn: -0.9434566\ttotal: 8.94s\tremaining: 13m 24s\n",
      "11:\tlearn: -0.9340283\ttotal: 9.83s\tremaining: 13m 29s\n",
      "12:\tlearn: -0.9248824\ttotal: 10.6s\tremaining: 13m 22s\n",
      "13:\tlearn: -0.9161777\ttotal: 11.4s\tremaining: 13m 20s\n",
      "14:\tlearn: -0.9081275\ttotal: 12.1s\tremaining: 13m 16s\n",
      "15:\tlearn: -0.9003958\ttotal: 12.9s\tremaining: 13m 11s\n",
      "16:\tlearn: -0.8931151\ttotal: 13.6s\tremaining: 13m 9s\n",
      "17:\tlearn: -0.8863696\ttotal: 14.4s\tremaining: 13m 4s\n",
      "18:\tlearn: -0.8799491\ttotal: 15.1s\tremaining: 12m 59s\n",
      "19:\tlearn: -0.8740213\ttotal: 15.8s\tremaining: 12m 55s\n",
      "20:\tlearn: -0.8682447\ttotal: 16.6s\tremaining: 12m 52s\n",
      "21:\tlearn: -0.8627352\ttotal: 17.3s\tremaining: 12m 51s\n",
      "22:\tlearn: -0.8576285\ttotal: 18.1s\tremaining: 12m 48s\n",
      "23:\tlearn: -0.8526983\ttotal: 18.8s\tremaining: 12m 45s\n",
      "24:\tlearn: -0.8480402\ttotal: 19.5s\tremaining: 12m 41s\n",
      "25:\tlearn: -0.8435965\ttotal: 20.4s\tremaining: 12m 45s\n",
      "26:\tlearn: -0.8393558\ttotal: 21.2s\tremaining: 12m 42s\n",
      "27:\tlearn: -0.8353863\ttotal: 22.2s\tremaining: 12m 50s\n",
      "28:\tlearn: -0.8316906\ttotal: 23.1s\tremaining: 12m 55s\n",
      "29:\tlearn: -0.8282583\ttotal: 24s\tremaining: 12m 55s\n",
      "30:\tlearn: -0.8248196\ttotal: 24.9s\tremaining: 12m 56s\n",
      "31:\tlearn: -0.8217106\ttotal: 25.7s\tremaining: 12m 58s\n",
      "32:\tlearn: -0.8187891\ttotal: 26.6s\tremaining: 13m\n",
      "33:\tlearn: -0.8158491\ttotal: 27.4s\tremaining: 12m 58s\n",
      "34:\tlearn: -0.8130542\ttotal: 28.2s\tremaining: 12m 58s\n",
      "35:\tlearn: -0.8102819\ttotal: 29s\tremaining: 12m 56s\n",
      "36:\tlearn: -0.8077290\ttotal: 29.8s\tremaining: 12m 54s\n",
      "37:\tlearn: -0.8053990\ttotal: 30.5s\tremaining: 12m 51s\n",
      "38:\tlearn: -0.8031514\ttotal: 31.2s\tremaining: 12m 49s\n",
      "39:\tlearn: -0.8008943\ttotal: 32s\tremaining: 12m 48s\n",
      "40:\tlearn: -0.7987113\ttotal: 32.9s\tremaining: 12m 49s\n",
      "41:\tlearn: -0.7967587\ttotal: 33.7s\tremaining: 12m 49s\n",
      "42:\tlearn: -0.7949372\ttotal: 34.5s\tremaining: 12m 48s\n",
      "43:\tlearn: -0.7931636\ttotal: 35.5s\tremaining: 12m 50s\n",
      "44:\tlearn: -0.7912229\ttotal: 36.3s\tremaining: 12m 50s\n",
      "45:\tlearn: -0.7894748\ttotal: 37.1s\tremaining: 12m 49s\n",
      "46:\tlearn: -0.7879325\ttotal: 37.8s\tremaining: 12m 46s\n",
      "47:\tlearn: -0.7864590\ttotal: 38.6s\tremaining: 12m 45s\n",
      "48:\tlearn: -0.7851627\ttotal: 39.4s\tremaining: 12m 44s\n",
      "49:\tlearn: -0.7836908\ttotal: 40.1s\tremaining: 12m 42s\n",
      "50:\tlearn: -0.7822306\ttotal: 40.9s\tremaining: 12m 40s\n",
      "51:\tlearn: -0.7809523\ttotal: 41.7s\tremaining: 12m 39s\n",
      "52:\tlearn: -0.7798510\ttotal: 42.5s\tremaining: 12m 39s\n",
      "53:\tlearn: -0.7785841\ttotal: 43.3s\tremaining: 12m 38s\n",
      "54:\tlearn: -0.7775830\ttotal: 44s\tremaining: 12m 35s\n",
      "55:\tlearn: -0.7764558\ttotal: 44.7s\tremaining: 12m 33s\n",
      "56:\tlearn: -0.7754745\ttotal: 45.4s\tremaining: 12m 31s\n",
      "57:\tlearn: -0.7745426\ttotal: 46.1s\tremaining: 12m 29s\n",
      "58:\tlearn: -0.7735780\ttotal: 46.9s\tremaining: 12m 28s\n",
      "59:\tlearn: -0.7724224\ttotal: 47.7s\tremaining: 12m 27s\n",
      "60:\tlearn: -0.7715137\ttotal: 48.4s\tremaining: 12m 24s\n",
      "61:\tlearn: -0.7705857\ttotal: 49.2s\tremaining: 12m 23s\n",
      "62:\tlearn: -0.7697034\ttotal: 49.9s\tremaining: 12m 22s\n",
      "63:\tlearn: -0.7688555\ttotal: 50.6s\tremaining: 12m 20s\n",
      "64:\tlearn: -0.7679245\ttotal: 51.4s\tremaining: 12m 19s\n",
      "65:\tlearn: -0.7669112\ttotal: 52.1s\tremaining: 12m 17s\n",
      "66:\tlearn: -0.7662986\ttotal: 52.8s\tremaining: 12m 15s\n",
      "67:\tlearn: -0.7656590\ttotal: 53.6s\tremaining: 12m 14s\n",
      "68:\tlearn: -0.7649588\ttotal: 54.3s\tremaining: 12m 12s\n",
      "69:\tlearn: -0.7643854\ttotal: 55s\tremaining: 12m 10s\n",
      "70:\tlearn: -0.7637681\ttotal: 55.7s\tremaining: 12m 9s\n",
      "71:\tlearn: -0.7630734\ttotal: 56.5s\tremaining: 12m 8s\n",
      "72:\tlearn: -0.7624567\ttotal: 57.2s\tremaining: 12m 6s\n",
      "73:\tlearn: -0.7618589\ttotal: 58s\tremaining: 12m 5s\n",
      "74:\tlearn: -0.7610174\ttotal: 58.7s\tremaining: 12m 4s\n",
      "75:\tlearn: -0.7601474\ttotal: 59.5s\tremaining: 12m 3s\n",
      "76:\tlearn: -0.7595811\ttotal: 1m\tremaining: 12m 3s\n",
      "77:\tlearn: -0.7589886\ttotal: 1m 1s\tremaining: 12m 2s\n",
      "78:\tlearn: -0.7584241\ttotal: 1m 1s\tremaining: 12m 1s\n",
      "79:\tlearn: -0.7580535\ttotal: 1m 2s\tremaining: 12m\n",
      "80:\tlearn: -0.7575226\ttotal: 1m 3s\tremaining: 11m 59s\n",
      "81:\tlearn: -0.7568903\ttotal: 1m 4s\tremaining: 11m 59s\n",
      "82:\tlearn: -0.7561731\ttotal: 1m 5s\tremaining: 11m 59s\n",
      "83:\tlearn: -0.7555328\ttotal: 1m 6s\tremaining: 12m\n",
      "84:\tlearn: -0.7548231\ttotal: 1m 6s\tremaining: 11m 59s\n",
      "85:\tlearn: -0.7544381\ttotal: 1m 7s\tremaining: 11m 58s\n",
      "86:\tlearn: -0.7541068\ttotal: 1m 8s\tremaining: 11m 57s\n",
      "87:\tlearn: -0.7533635\ttotal: 1m 9s\tremaining: 11m 56s\n",
      "88:\tlearn: -0.7528498\ttotal: 1m 9s\tremaining: 11m 56s\n",
      "89:\tlearn: -0.7522183\ttotal: 1m 10s\tremaining: 11m 56s\n",
      "90:\tlearn: -0.7518363\ttotal: 1m 11s\tremaining: 11m 54s\n",
      "91:\tlearn: -0.7513048\ttotal: 1m 12s\tremaining: 11m 53s\n",
      "92:\tlearn: -0.7507925\ttotal: 1m 13s\tremaining: 11m 52s\n",
      "93:\tlearn: -0.7503556\ttotal: 1m 13s\tremaining: 11m 51s\n",
      "94:\tlearn: -0.7499895\ttotal: 1m 14s\tremaining: 11m 50s\n",
      "95:\tlearn: -0.7492283\ttotal: 1m 15s\tremaining: 11m 49s\n",
      "96:\tlearn: -0.7487881\ttotal: 1m 16s\tremaining: 11m 48s\n",
      "97:\tlearn: -0.7481893\ttotal: 1m 16s\tremaining: 11m 47s\n",
      "98:\tlearn: -0.7475753\ttotal: 1m 17s\tremaining: 11m 49s\n",
      "99:\tlearn: -0.7471765\ttotal: 1m 18s\tremaining: 11m 49s\n",
      "100:\tlearn: -0.7468865\ttotal: 1m 19s\tremaining: 11m 48s\n",
      "101:\tlearn: -0.7464535\ttotal: 1m 20s\tremaining: 11m 48s\n",
      "102:\tlearn: -0.7459763\ttotal: 1m 21s\tremaining: 11m 47s\n",
      "103:\tlearn: -0.7455692\ttotal: 1m 22s\tremaining: 11m 47s\n",
      "104:\tlearn: -0.7451767\ttotal: 1m 22s\tremaining: 11m 47s\n",
      "105:\tlearn: -0.7449246\ttotal: 1m 23s\tremaining: 11m 46s\n",
      "106:\tlearn: -0.7445094\ttotal: 1m 24s\tremaining: 11m 45s\n",
      "107:\tlearn: -0.7441267\ttotal: 1m 25s\tremaining: 11m 44s\n",
      "108:\tlearn: -0.7435435\ttotal: 1m 26s\tremaining: 11m 43s\n",
      "109:\tlearn: -0.7431994\ttotal: 1m 26s\tremaining: 11m 42s\n",
      "110:\tlearn: -0.7428778\ttotal: 1m 27s\tremaining: 11m 41s\n",
      "111:\tlearn: -0.7424409\ttotal: 1m 28s\tremaining: 11m 40s\n",
      "112:\tlearn: -0.7420310\ttotal: 1m 29s\tremaining: 11m 39s\n",
      "113:\tlearn: -0.7414542\ttotal: 1m 29s\tremaining: 11m 38s\n",
      "114:\tlearn: -0.7410577\ttotal: 1m 30s\tremaining: 11m 37s\n",
      "115:\tlearn: -0.7408097\ttotal: 1m 31s\tremaining: 11m 37s\n",
      "116:\tlearn: -0.7406602\ttotal: 1m 32s\tremaining: 11m 38s\n",
      "117:\tlearn: -0.7400086\ttotal: 1m 33s\tremaining: 11m 40s\n",
      "118:\tlearn: -0.7395649\ttotal: 1m 34s\tremaining: 11m 40s\n",
      "119:\tlearn: -0.7389585\ttotal: 1m 35s\tremaining: 11m 41s\n",
      "120:\tlearn: -0.7384303\ttotal: 1m 36s\tremaining: 11m 41s\n",
      "121:\tlearn: -0.7380192\ttotal: 1m 37s\tremaining: 11m 40s\n",
      "122:\tlearn: -0.7376111\ttotal: 1m 38s\tremaining: 11m 42s\n",
      "123:\tlearn: -0.7373819\ttotal: 1m 39s\tremaining: 11m 41s\n",
      "124:\tlearn: -0.7371316\ttotal: 1m 40s\tremaining: 11m 41s\n",
      "125:\tlearn: -0.7368057\ttotal: 1m 40s\tremaining: 11m 40s\n",
      "126:\tlearn: -0.7362845\ttotal: 1m 41s\tremaining: 11m 40s\n",
      "127:\tlearn: -0.7360036\ttotal: 1m 42s\tremaining: 11m 40s\n",
      "128:\tlearn: -0.7357819\ttotal: 1m 43s\tremaining: 11m 37s\n",
      "129:\tlearn: -0.7354780\ttotal: 1m 44s\tremaining: 11m 37s\n",
      "130:\tlearn: -0.7350452\ttotal: 1m 45s\tremaining: 11m 38s\n",
      "131:\tlearn: -0.7347969\ttotal: 1m 46s\tremaining: 11m 38s\n",
      "132:\tlearn: -0.7342816\ttotal: 1m 47s\tremaining: 11m 38s\n",
      "133:\tlearn: -0.7340151\ttotal: 1m 48s\tremaining: 11m 38s\n",
      "134:\tlearn: -0.7337368\ttotal: 1m 48s\tremaining: 11m 37s\n",
      "135:\tlearn: -0.7332949\ttotal: 1m 49s\tremaining: 11m 37s\n",
      "136:\tlearn: -0.7329797\ttotal: 1m 50s\tremaining: 11m 36s\n",
      "137:\tlearn: -0.7324023\ttotal: 1m 51s\tremaining: 11m 36s\n",
      "138:\tlearn: -0.7318516\ttotal: 1m 52s\tremaining: 11m 35s\n",
      "139:\tlearn: -0.7315146\ttotal: 1m 53s\tremaining: 11m 35s\n",
      "140:\tlearn: -0.7310767\ttotal: 1m 54s\tremaining: 11m 34s\n",
      "141:\tlearn: -0.7307006\ttotal: 1m 54s\tremaining: 11m 34s\n",
      "142:\tlearn: -0.7304174\ttotal: 1m 56s\tremaining: 11m 35s\n",
      "143:\tlearn: -0.7299663\ttotal: 1m 57s\tremaining: 11m 36s\n",
      "144:\tlearn: -0.7296821\ttotal: 1m 58s\tremaining: 11m 36s\n",
      "145:\tlearn: -0.7291530\ttotal: 1m 59s\tremaining: 11m 36s\n",
      "146:\tlearn: -0.7286997\ttotal: 1m 59s\tremaining: 11m 36s\n",
      "147:\tlearn: -0.7285313\ttotal: 2m\tremaining: 11m 34s\n",
      "148:\tlearn: -0.7282009\ttotal: 2m 1s\tremaining: 11m 33s\n",
      "149:\tlearn: -0.7277410\ttotal: 2m 2s\tremaining: 11m 33s\n",
      "150:\tlearn: -0.7273002\ttotal: 2m 3s\tremaining: 11m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151:\tlearn: -0.7268699\ttotal: 2m 4s\tremaining: 11m 32s\n",
      "152:\tlearn: -0.7265965\ttotal: 2m 4s\tremaining: 11m 31s\n",
      "153:\tlearn: -0.7258230\ttotal: 2m 5s\tremaining: 11m 32s\n",
      "154:\tlearn: -0.7253673\ttotal: 2m 6s\tremaining: 11m 31s\n",
      "155:\tlearn: -0.7251759\ttotal: 2m 7s\tremaining: 11m 30s\n",
      "156:\tlearn: -0.7249079\ttotal: 2m 8s\tremaining: 11m 29s\n",
      "157:\tlearn: -0.7244387\ttotal: 2m 9s\tremaining: 11m 27s\n",
      "158:\tlearn: -0.7239337\ttotal: 2m 9s\tremaining: 11m 27s\n",
      "159:\tlearn: -0.7234928\ttotal: 2m 10s\tremaining: 11m 26s\n",
      "160:\tlearn: -0.7232288\ttotal: 2m 11s\tremaining: 11m 24s\n",
      "161:\tlearn: -0.7223201\ttotal: 2m 12s\tremaining: 11m 24s\n",
      "162:\tlearn: -0.7218534\ttotal: 2m 12s\tremaining: 11m 22s\n",
      "163:\tlearn: -0.7215413\ttotal: 2m 13s\tremaining: 11m 21s\n",
      "164:\tlearn: -0.7210852\ttotal: 2m 14s\tremaining: 11m 20s\n",
      "165:\tlearn: -0.7203074\ttotal: 2m 15s\tremaining: 11m 19s\n",
      "166:\tlearn: -0.7199913\ttotal: 2m 16s\tremaining: 11m 18s\n",
      "167:\tlearn: -0.7195063\ttotal: 2m 16s\tremaining: 11m 17s\n",
      "168:\tlearn: -0.7190454\ttotal: 2m 17s\tremaining: 11m 16s\n",
      "169:\tlearn: -0.7186159\ttotal: 2m 18s\tremaining: 11m 16s\n",
      "170:\tlearn: -0.7183783\ttotal: 2m 19s\tremaining: 11m 14s\n",
      "171:\tlearn: -0.7180572\ttotal: 2m 19s\tremaining: 11m 13s\n",
      "172:\tlearn: -0.7176514\ttotal: 2m 20s\tremaining: 11m 13s\n",
      "173:\tlearn: -0.7172104\ttotal: 2m 21s\tremaining: 11m 11s\n",
      "174:\tlearn: -0.7169054\ttotal: 2m 22s\tremaining: 11m 10s\n",
      "175:\tlearn: -0.7164556\ttotal: 2m 23s\tremaining: 11m 9s\n",
      "176:\tlearn: -0.7160420\ttotal: 2m 23s\tremaining: 11m 9s\n",
      "177:\tlearn: -0.7154883\ttotal: 2m 24s\tremaining: 11m 8s\n",
      "178:\tlearn: -0.7151898\ttotal: 2m 25s\tremaining: 11m 7s\n",
      "179:\tlearn: -0.7149484\ttotal: 2m 26s\tremaining: 11m 7s\n",
      "180:\tlearn: -0.7147222\ttotal: 2m 27s\tremaining: 11m 8s\n",
      "181:\tlearn: -0.7142006\ttotal: 2m 28s\tremaining: 11m 9s\n",
      "182:\tlearn: -0.7137584\ttotal: 2m 29s\tremaining: 11m 9s\n",
      "183:\tlearn: -0.7135157\ttotal: 2m 30s\tremaining: 11m 8s\n",
      "184:\tlearn: -0.7129771\ttotal: 2m 31s\tremaining: 11m 8s\n",
      "185:\tlearn: -0.7127198\ttotal: 2m 32s\tremaining: 11m 7s\n",
      "186:\tlearn: -0.7124178\ttotal: 2m 33s\tremaining: 11m 6s\n",
      "187:\tlearn: -0.7119948\ttotal: 2m 34s\tremaining: 11m 5s\n",
      "188:\tlearn: -0.7116073\ttotal: 2m 34s\tremaining: 11m 4s\n",
      "189:\tlearn: -0.7113296\ttotal: 2m 35s\tremaining: 11m 3s\n",
      "190:\tlearn: -0.7109183\ttotal: 2m 36s\tremaining: 11m 2s\n",
      "191:\tlearn: -0.7105018\ttotal: 2m 37s\tremaining: 11m 2s\n",
      "192:\tlearn: -0.7101768\ttotal: 2m 38s\tremaining: 11m 1s\n",
      "193:\tlearn: -0.7100006\ttotal: 2m 38s\tremaining: 11m\n",
      "194:\tlearn: -0.7095384\ttotal: 2m 39s\tremaining: 10m 58s\n",
      "195:\tlearn: -0.7091265\ttotal: 2m 40s\tremaining: 10m 57s\n",
      "196:\tlearn: -0.7087313\ttotal: 2m 41s\tremaining: 10m 56s\n",
      "197:\tlearn: -0.7083891\ttotal: 2m 41s\tremaining: 10m 55s\n",
      "198:\tlearn: -0.7082102\ttotal: 2m 42s\tremaining: 10m 54s\n",
      "199:\tlearn: -0.7079295\ttotal: 2m 43s\tremaining: 10m 53s\n",
      "200:\tlearn: -0.7076042\ttotal: 2m 44s\tremaining: 10m 52s\n",
      "201:\tlearn: -0.7072577\ttotal: 2m 44s\tremaining: 10m 51s\n",
      "202:\tlearn: -0.7067841\ttotal: 2m 45s\tremaining: 10m 49s\n",
      "203:\tlearn: -0.7066005\ttotal: 2m 46s\tremaining: 10m 48s\n",
      "204:\tlearn: -0.7058867\ttotal: 2m 47s\tremaining: 10m 47s\n",
      "205:\tlearn: -0.7055172\ttotal: 2m 47s\tremaining: 10m 46s\n",
      "206:\tlearn: -0.7052473\ttotal: 2m 48s\tremaining: 10m 45s\n",
      "207:\tlearn: -0.7049144\ttotal: 2m 49s\tremaining: 10m 44s\n",
      "208:\tlearn: -0.7046714\ttotal: 2m 49s\tremaining: 10m 42s\n",
      "209:\tlearn: -0.7042580\ttotal: 2m 50s\tremaining: 10m 41s\n",
      "210:\tlearn: -0.7039074\ttotal: 2m 51s\tremaining: 10m 40s\n",
      "211:\tlearn: -0.7036297\ttotal: 2m 52s\tremaining: 10m 39s\n",
      "212:\tlearn: -0.7033301\ttotal: 2m 52s\tremaining: 10m 39s\n",
      "213:\tlearn: -0.7029776\ttotal: 2m 53s\tremaining: 10m 38s\n",
      "214:\tlearn: -0.7026394\ttotal: 2m 54s\tremaining: 10m 36s\n",
      "215:\tlearn: -0.7023364\ttotal: 2m 55s\tremaining: 10m 35s\n",
      "216:\tlearn: -0.7019422\ttotal: 2m 55s\tremaining: 10m 34s\n",
      "217:\tlearn: -0.7016449\ttotal: 2m 56s\tremaining: 10m 33s\n",
      "218:\tlearn: -0.7013641\ttotal: 2m 57s\tremaining: 10m 32s\n",
      "219:\tlearn: -0.7010839\ttotal: 2m 58s\tremaining: 10m 31s\n",
      "220:\tlearn: -0.7006872\ttotal: 2m 58s\tremaining: 10m 30s\n",
      "221:\tlearn: -0.7001761\ttotal: 2m 59s\tremaining: 10m 30s\n",
      "222:\tlearn: -0.6998230\ttotal: 3m\tremaining: 10m 29s\n",
      "223:\tlearn: -0.6993583\ttotal: 3m 1s\tremaining: 10m 28s\n",
      "224:\tlearn: -0.6991524\ttotal: 3m 2s\tremaining: 10m 27s\n",
      "225:\tlearn: -0.6987957\ttotal: 3m 3s\tremaining: 10m 26s\n",
      "226:\tlearn: -0.6984113\ttotal: 3m 3s\tremaining: 10m 26s\n",
      "227:\tlearn: -0.6978892\ttotal: 3m 4s\tremaining: 10m 25s\n",
      "228:\tlearn: -0.6978209\ttotal: 3m 4s\tremaining: 10m 22s\n",
      "229:\tlearn: -0.6975082\ttotal: 3m 5s\tremaining: 10m 21s\n",
      "230:\tlearn: -0.6973377\ttotal: 3m 6s\tremaining: 10m 20s\n",
      "231:\tlearn: -0.6971267\ttotal: 3m 7s\tremaining: 10m 19s\n",
      "232:\tlearn: -0.6969454\ttotal: 3m 7s\tremaining: 10m 18s\n",
      "233:\tlearn: -0.6965167\ttotal: 3m 8s\tremaining: 10m 17s\n",
      "234:\tlearn: -0.6963374\ttotal: 3m 9s\tremaining: 10m 16s\n",
      "235:\tlearn: -0.6962286\ttotal: 3m 10s\tremaining: 10m 15s\n",
      "236:\tlearn: -0.6959182\ttotal: 3m 11s\tremaining: 10m 14s\n",
      "237:\tlearn: -0.6955391\ttotal: 3m 11s\tremaining: 10m 14s\n",
      "238:\tlearn: -0.6953870\ttotal: 3m 12s\tremaining: 10m 13s\n",
      "239:\tlearn: -0.6950576\ttotal: 3m 13s\tremaining: 10m 12s\n",
      "240:\tlearn: -0.6946593\ttotal: 3m 14s\tremaining: 10m 11s\n",
      "241:\tlearn: -0.6944925\ttotal: 3m 15s\tremaining: 10m 11s\n",
      "242:\tlearn: -0.6940851\ttotal: 3m 15s\tremaining: 10m 10s\n",
      "243:\tlearn: -0.6939377\ttotal: 3m 16s\tremaining: 10m 9s\n",
      "244:\tlearn: -0.6935411\ttotal: 3m 17s\tremaining: 10m 8s\n",
      "245:\tlearn: -0.6933892\ttotal: 3m 18s\tremaining: 10m 7s\n",
      "246:\tlearn: -0.6931248\ttotal: 3m 19s\tremaining: 10m 7s\n",
      "247:\tlearn: -0.6925627\ttotal: 3m 20s\tremaining: 10m 6s\n",
      "248:\tlearn: -0.6922900\ttotal: 3m 20s\tremaining: 10m 5s\n",
      "249:\tlearn: -0.6920557\ttotal: 3m 21s\tremaining: 10m 4s\n",
      "250:\tlearn: -0.6917982\ttotal: 3m 22s\tremaining: 10m 3s\n",
      "251:\tlearn: -0.6914842\ttotal: 3m 23s\tremaining: 10m 2s\n",
      "252:\tlearn: -0.6912357\ttotal: 3m 23s\tremaining: 10m 2s\n",
      "253:\tlearn: -0.6911417\ttotal: 3m 24s\tremaining: 10m\n",
      "254:\tlearn: -0.6908731\ttotal: 3m 25s\tremaining: 10m\n",
      "255:\tlearn: -0.6906937\ttotal: 3m 26s\tremaining: 9m 59s\n",
      "256:\tlearn: -0.6904808\ttotal: 3m 26s\tremaining: 9m 58s\n",
      "257:\tlearn: -0.6901953\ttotal: 3m 27s\tremaining: 9m 57s\n",
      "258:\tlearn: -0.6899326\ttotal: 3m 28s\tremaining: 9m 56s\n",
      "259:\tlearn: -0.6895633\ttotal: 3m 29s\tremaining: 9m 55s\n",
      "260:\tlearn: -0.6891423\ttotal: 3m 29s\tremaining: 9m 54s\n",
      "261:\tlearn: -0.6888309\ttotal: 3m 30s\tremaining: 9m 53s\n",
      "262:\tlearn: -0.6886204\ttotal: 3m 31s\tremaining: 9m 52s\n",
      "263:\tlearn: -0.6882367\ttotal: 3m 32s\tremaining: 9m 51s\n",
      "264:\tlearn: -0.6880725\ttotal: 3m 33s\tremaining: 9m 50s\n",
      "265:\tlearn: -0.6878718\ttotal: 3m 33s\tremaining: 9m 50s\n",
      "266:\tlearn: -0.6875243\ttotal: 3m 34s\tremaining: 9m 49s\n",
      "267:\tlearn: -0.6874544\ttotal: 3m 35s\tremaining: 9m 48s\n",
      "268:\tlearn: -0.6871843\ttotal: 3m 36s\tremaining: 9m 47s\n",
      "269:\tlearn: -0.6870075\ttotal: 3m 36s\tremaining: 9m 46s\n",
      "270:\tlearn: -0.6867724\ttotal: 3m 37s\tremaining: 9m 45s\n",
      "271:\tlearn: -0.6864634\ttotal: 3m 38s\tremaining: 9m 44s\n",
      "272:\tlearn: -0.6861509\ttotal: 3m 39s\tremaining: 9m 43s\n",
      "273:\tlearn: -0.6857830\ttotal: 3m 39s\tremaining: 9m 42s\n",
      "274:\tlearn: -0.6854365\ttotal: 3m 40s\tremaining: 9m 42s\n",
      "275:\tlearn: -0.6851615\ttotal: 3m 41s\tremaining: 9m 41s\n",
      "276:\tlearn: -0.6846170\ttotal: 3m 42s\tremaining: 9m 40s\n",
      "277:\tlearn: -0.6843913\ttotal: 3m 43s\tremaining: 9m 39s\n",
      "278:\tlearn: -0.6841055\ttotal: 3m 43s\tremaining: 9m 38s\n",
      "279:\tlearn: -0.6837118\ttotal: 3m 44s\tremaining: 9m 37s\n",
      "280:\tlearn: -0.6835783\ttotal: 3m 45s\tremaining: 9m 36s\n",
      "281:\tlearn: -0.6834906\ttotal: 3m 46s\tremaining: 9m 35s\n",
      "282:\tlearn: -0.6831932\ttotal: 3m 46s\tremaining: 9m 34s\n",
      "283:\tlearn: -0.6829159\ttotal: 3m 47s\tremaining: 9m 33s\n",
      "284:\tlearn: -0.6825159\ttotal: 3m 48s\tremaining: 9m 32s\n",
      "285:\tlearn: -0.6820825\ttotal: 3m 49s\tremaining: 9m 31s\n",
      "286:\tlearn: -0.6819097\ttotal: 3m 49s\tremaining: 9m 31s\n",
      "287:\tlearn: -0.6814689\ttotal: 3m 50s\tremaining: 9m 30s\n",
      "288:\tlearn: -0.6812141\ttotal: 3m 51s\tremaining: 9m 29s\n",
      "289:\tlearn: -0.6809614\ttotal: 3m 52s\tremaining: 9m 28s\n",
      "290:\tlearn: -0.6806420\ttotal: 3m 52s\tremaining: 9m 27s\n",
      "291:\tlearn: -0.6804068\ttotal: 3m 53s\tremaining: 9m 26s\n",
      "292:\tlearn: -0.6801982\ttotal: 3m 54s\tremaining: 9m 25s\n",
      "293:\tlearn: -0.6798969\ttotal: 3m 55s\tremaining: 9m 24s\n",
      "294:\tlearn: -0.6795806\ttotal: 3m 55s\tremaining: 9m 23s\n",
      "295:\tlearn: -0.6794280\ttotal: 3m 56s\tremaining: 9m 22s\n",
      "296:\tlearn: -0.6790605\ttotal: 3m 57s\tremaining: 9m 22s\n",
      "297:\tlearn: -0.6788112\ttotal: 3m 58s\tremaining: 9m 21s\n",
      "298:\tlearn: -0.6785680\ttotal: 3m 58s\tremaining: 9m 20s\n",
      "299:\tlearn: -0.6783310\ttotal: 3m 59s\tremaining: 9m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300:\tlearn: -0.6781125\ttotal: 4m\tremaining: 9m 18s\n",
      "301:\tlearn: -0.6778166\ttotal: 4m 1s\tremaining: 9m 17s\n",
      "302:\tlearn: -0.6774763\ttotal: 4m 1s\tremaining: 9m 16s\n",
      "303:\tlearn: -0.6771925\ttotal: 4m 2s\tremaining: 9m 15s\n",
      "304:\tlearn: -0.6768237\ttotal: 4m 3s\tremaining: 9m 14s\n",
      "305:\tlearn: -0.6765559\ttotal: 4m 4s\tremaining: 9m 13s\n",
      "306:\tlearn: -0.6763847\ttotal: 4m 4s\tremaining: 9m 12s\n",
      "307:\tlearn: -0.6761619\ttotal: 4m 5s\tremaining: 9m 11s\n",
      "308:\tlearn: -0.6758830\ttotal: 4m 6s\tremaining: 9m 10s\n",
      "309:\tlearn: -0.6755749\ttotal: 4m 7s\tremaining: 9m 9s\n",
      "310:\tlearn: -0.6751791\ttotal: 4m 7s\tremaining: 9m 9s\n",
      "311:\tlearn: -0.6750297\ttotal: 4m 8s\tremaining: 9m 8s\n",
      "312:\tlearn: -0.6747846\ttotal: 4m 9s\tremaining: 9m 7s\n",
      "313:\tlearn: -0.6746347\ttotal: 4m 9s\tremaining: 9m 6s\n",
      "314:\tlearn: -0.6743808\ttotal: 4m 10s\tremaining: 9m 5s\n",
      "315:\tlearn: -0.6741294\ttotal: 4m 11s\tremaining: 9m 4s\n",
      "316:\tlearn: -0.6738665\ttotal: 4m 12s\tremaining: 9m 3s\n",
      "317:\tlearn: -0.6735620\ttotal: 4m 13s\tremaining: 9m 2s\n",
      "318:\tlearn: -0.6732737\ttotal: 4m 13s\tremaining: 9m 1s\n",
      "319:\tlearn: -0.6729778\ttotal: 4m 14s\tremaining: 9m\n",
      "320:\tlearn: -0.6726919\ttotal: 4m 15s\tremaining: 8m 59s\n",
      "321:\tlearn: -0.6723699\ttotal: 4m 16s\tremaining: 8m 59s\n",
      "322:\tlearn: -0.6721919\ttotal: 4m 16s\tremaining: 8m 58s\n",
      "323:\tlearn: -0.6717917\ttotal: 4m 17s\tremaining: 8m 57s\n",
      "324:\tlearn: -0.6714535\ttotal: 4m 18s\tremaining: 8m 56s\n",
      "325:\tlearn: -0.6712021\ttotal: 4m 18s\tremaining: 8m 55s\n",
      "326:\tlearn: -0.6707922\ttotal: 4m 19s\tremaining: 8m 54s\n",
      "327:\tlearn: -0.6706015\ttotal: 4m 20s\tremaining: 8m 53s\n",
      "328:\tlearn: -0.6702963\ttotal: 4m 21s\tremaining: 8m 53s\n",
      "329:\tlearn: -0.6698996\ttotal: 4m 22s\tremaining: 8m 52s\n",
      "330:\tlearn: -0.6696519\ttotal: 4m 22s\tremaining: 8m 51s\n",
      "331:\tlearn: -0.6694030\ttotal: 4m 23s\tremaining: 8m 50s\n",
      "332:\tlearn: -0.6692877\ttotal: 4m 24s\tremaining: 8m 49s\n",
      "333:\tlearn: -0.6691248\ttotal: 4m 25s\tremaining: 8m 49s\n",
      "334:\tlearn: -0.6687617\ttotal: 4m 26s\tremaining: 8m 48s\n",
      "335:\tlearn: -0.6684796\ttotal: 4m 26s\tremaining: 8m 47s\n",
      "336:\tlearn: -0.6681962\ttotal: 4m 27s\tremaining: 8m 46s\n",
      "337:\tlearn: -0.6676291\ttotal: 4m 28s\tremaining: 8m 45s\n",
      "338:\tlearn: -0.6671512\ttotal: 4m 29s\tremaining: 8m 44s\n",
      "339:\tlearn: -0.6666064\ttotal: 4m 29s\tremaining: 8m 43s\n",
      "340:\tlearn: -0.6660843\ttotal: 4m 30s\tremaining: 8m 43s\n",
      "341:\tlearn: -0.6657351\ttotal: 4m 31s\tremaining: 8m 42s\n",
      "342:\tlearn: -0.6654081\ttotal: 4m 32s\tremaining: 8m 41s\n",
      "343:\tlearn: -0.6652848\ttotal: 4m 32s\tremaining: 8m 40s\n",
      "344:\tlearn: -0.6649032\ttotal: 4m 33s\tremaining: 8m 39s\n",
      "345:\tlearn: -0.6646327\ttotal: 4m 34s\tremaining: 8m 38s\n",
      "346:\tlearn: -0.6644235\ttotal: 4m 35s\tremaining: 8m 37s\n",
      "347:\tlearn: -0.6638851\ttotal: 4m 35s\tremaining: 8m 36s\n",
      "348:\tlearn: -0.6636176\ttotal: 4m 36s\tremaining: 8m 35s\n",
      "349:\tlearn: -0.6633272\ttotal: 4m 37s\tremaining: 8m 35s\n",
      "350:\tlearn: -0.6630388\ttotal: 4m 38s\tremaining: 8m 34s\n",
      "351:\tlearn: -0.6629442\ttotal: 4m 38s\tremaining: 8m 33s\n",
      "352:\tlearn: -0.6624448\ttotal: 4m 39s\tremaining: 8m 32s\n",
      "353:\tlearn: -0.6622792\ttotal: 4m 40s\tremaining: 8m 31s\n",
      "354:\tlearn: -0.6619898\ttotal: 4m 41s\tremaining: 8m 30s\n",
      "355:\tlearn: -0.6616806\ttotal: 4m 41s\tremaining: 8m 29s\n",
      "356:\tlearn: -0.6614834\ttotal: 4m 42s\tremaining: 8m 28s\n",
      "357:\tlearn: -0.6612889\ttotal: 4m 43s\tremaining: 8m 27s\n",
      "358:\tlearn: -0.6610203\ttotal: 4m 43s\tremaining: 8m 26s\n",
      "359:\tlearn: -0.6607710\ttotal: 4m 44s\tremaining: 8m 26s\n",
      "360:\tlearn: -0.6602822\ttotal: 4m 45s\tremaining: 8m 25s\n",
      "361:\tlearn: -0.6600076\ttotal: 4m 46s\tremaining: 8m 24s\n",
      "362:\tlearn: -0.6595238\ttotal: 4m 46s\tremaining: 8m 23s\n",
      "363:\tlearn: -0.6591650\ttotal: 4m 47s\tremaining: 8m 22s\n",
      "364:\tlearn: -0.6588336\ttotal: 4m 48s\tremaining: 8m 21s\n",
      "365:\tlearn: -0.6585701\ttotal: 4m 49s\tremaining: 8m 20s\n",
      "366:\tlearn: -0.6583332\ttotal: 4m 49s\tremaining: 8m 19s\n",
      "367:\tlearn: -0.6580741\ttotal: 4m 50s\tremaining: 8m 19s\n",
      "368:\tlearn: -0.6578800\ttotal: 4m 51s\tremaining: 8m 18s\n",
      "369:\tlearn: -0.6576173\ttotal: 4m 52s\tremaining: 8m 17s\n",
      "370:\tlearn: -0.6571960\ttotal: 4m 52s\tremaining: 8m 16s\n",
      "371:\tlearn: -0.6569375\ttotal: 4m 53s\tremaining: 8m 15s\n",
      "372:\tlearn: -0.6567660\ttotal: 4m 54s\tremaining: 8m 14s\n",
      "373:\tlearn: -0.6564301\ttotal: 4m 55s\tremaining: 8m 13s\n",
      "374:\tlearn: -0.6561870\ttotal: 4m 55s\tremaining: 8m 12s\n",
      "375:\tlearn: -0.6558782\ttotal: 4m 56s\tremaining: 8m 12s\n",
      "376:\tlearn: -0.6555979\ttotal: 4m 57s\tremaining: 8m 11s\n",
      "377:\tlearn: -0.6553033\ttotal: 4m 57s\tremaining: 8m 10s\n",
      "378:\tlearn: -0.6550320\ttotal: 4m 58s\tremaining: 8m 9s\n",
      "379:\tlearn: -0.6546636\ttotal: 4m 59s\tremaining: 8m 8s\n",
      "380:\tlearn: -0.6544157\ttotal: 5m\tremaining: 8m 7s\n",
      "381:\tlearn: -0.6540560\ttotal: 5m\tremaining: 8m 6s\n",
      "382:\tlearn: -0.6537011\ttotal: 5m 1s\tremaining: 8m 5s\n",
      "383:\tlearn: -0.6534907\ttotal: 5m 2s\tremaining: 8m 5s\n",
      "384:\tlearn: -0.6530840\ttotal: 5m 3s\tremaining: 8m 4s\n",
      "385:\tlearn: -0.6529347\ttotal: 5m 3s\tremaining: 8m 3s\n",
      "386:\tlearn: -0.6527882\ttotal: 5m 4s\tremaining: 8m 2s\n",
      "387:\tlearn: -0.6525336\ttotal: 5m 5s\tremaining: 8m 1s\n",
      "388:\tlearn: -0.6522737\ttotal: 5m 6s\tremaining: 8m\n",
      "389:\tlearn: -0.6520304\ttotal: 5m 6s\tremaining: 7m 59s\n",
      "390:\tlearn: -0.6517140\ttotal: 5m 7s\tremaining: 7m 58s\n",
      "391:\tlearn: -0.6515511\ttotal: 5m 8s\tremaining: 7m 58s\n",
      "392:\tlearn: -0.6511056\ttotal: 5m 9s\tremaining: 7m 57s\n",
      "393:\tlearn: -0.6509497\ttotal: 5m 9s\tremaining: 7m 56s\n",
      "394:\tlearn: -0.6506181\ttotal: 5m 10s\tremaining: 7m 55s\n",
      "395:\tlearn: -0.6503218\ttotal: 5m 11s\tremaining: 7m 54s\n",
      "396:\tlearn: -0.6500243\ttotal: 5m 12s\tremaining: 7m 53s\n",
      "397:\tlearn: -0.6497022\ttotal: 5m 12s\tremaining: 7m 53s\n",
      "398:\tlearn: -0.6494560\ttotal: 5m 13s\tremaining: 7m 52s\n",
      "399:\tlearn: -0.6492677\ttotal: 5m 14s\tremaining: 7m 51s\n",
      "400:\tlearn: -0.6489325\ttotal: 5m 15s\tremaining: 7m 50s\n",
      "401:\tlearn: -0.6485596\ttotal: 5m 15s\tremaining: 7m 49s\n",
      "402:\tlearn: -0.6484056\ttotal: 5m 16s\tremaining: 7m 48s\n",
      "403:\tlearn: -0.6480919\ttotal: 5m 17s\tremaining: 7m 47s\n",
      "404:\tlearn: -0.6478874\ttotal: 5m 17s\tremaining: 7m 47s\n",
      "405:\tlearn: -0.6474612\ttotal: 5m 18s\tremaining: 7m 46s\n",
      "406:\tlearn: -0.6473067\ttotal: 5m 19s\tremaining: 7m 45s\n",
      "407:\tlearn: -0.6470283\ttotal: 5m 20s\tremaining: 7m 44s\n",
      "408:\tlearn: -0.6467804\ttotal: 5m 20s\tremaining: 7m 43s\n",
      "409:\tlearn: -0.6466048\ttotal: 5m 21s\tremaining: 7m 42s\n",
      "410:\tlearn: -0.6463286\ttotal: 5m 22s\tremaining: 7m 42s\n",
      "411:\tlearn: -0.6462263\ttotal: 5m 23s\tremaining: 7m 41s\n",
      "412:\tlearn: -0.6458429\ttotal: 5m 23s\tremaining: 7m 40s\n",
      "413:\tlearn: -0.6456729\ttotal: 5m 24s\tremaining: 7m 39s\n",
      "414:\tlearn: -0.6454550\ttotal: 5m 25s\tremaining: 7m 38s\n",
      "415:\tlearn: -0.6448957\ttotal: 5m 26s\tremaining: 7m 38s\n",
      "416:\tlearn: -0.6445381\ttotal: 5m 27s\tremaining: 7m 37s\n",
      "417:\tlearn: -0.6440829\ttotal: 5m 28s\tremaining: 7m 37s\n",
      "418:\tlearn: -0.6439361\ttotal: 5m 29s\tremaining: 7m 36s\n",
      "419:\tlearn: -0.6437741\ttotal: 5m 29s\tremaining: 7m 35s\n",
      "420:\tlearn: -0.6435319\ttotal: 5m 30s\tremaining: 7m 34s\n",
      "421:\tlearn: -0.6429979\ttotal: 5m 31s\tremaining: 7m 34s\n",
      "422:\tlearn: -0.6426911\ttotal: 5m 32s\tremaining: 7m 33s\n",
      "423:\tlearn: -0.6424278\ttotal: 5m 33s\tremaining: 7m 32s\n",
      "424:\tlearn: -0.6422253\ttotal: 5m 33s\tremaining: 7m 31s\n",
      "425:\tlearn: -0.6418422\ttotal: 5m 34s\tremaining: 7m 31s\n",
      "426:\tlearn: -0.6415156\ttotal: 5m 35s\tremaining: 7m 30s\n",
      "427:\tlearn: -0.6410053\ttotal: 5m 36s\tremaining: 7m 29s\n",
      "428:\tlearn: -0.6404370\ttotal: 5m 37s\tremaining: 7m 28s\n",
      "429:\tlearn: -0.6402570\ttotal: 5m 38s\tremaining: 7m 28s\n",
      "430:\tlearn: -0.6397697\ttotal: 5m 38s\tremaining: 7m 27s\n",
      "431:\tlearn: -0.6395734\ttotal: 5m 39s\tremaining: 7m 26s\n",
      "432:\tlearn: -0.6392712\ttotal: 5m 40s\tremaining: 7m 25s\n",
      "433:\tlearn: -0.6388684\ttotal: 5m 40s\tremaining: 7m 24s\n",
      "434:\tlearn: -0.6385822\ttotal: 5m 41s\tremaining: 7m 23s\n",
      "435:\tlearn: -0.6383148\ttotal: 5m 42s\tremaining: 7m 23s\n",
      "436:\tlearn: -0.6379400\ttotal: 5m 43s\tremaining: 7m 22s\n",
      "437:\tlearn: -0.6373968\ttotal: 5m 44s\tremaining: 7m 21s\n",
      "438:\tlearn: -0.6372430\ttotal: 5m 44s\tremaining: 7m 20s\n",
      "439:\tlearn: -0.6370010\ttotal: 5m 45s\tremaining: 7m 19s\n",
      "440:\tlearn: -0.6367840\ttotal: 5m 46s\tremaining: 7m 19s\n",
      "441:\tlearn: -0.6366109\ttotal: 5m 47s\tremaining: 7m 18s\n",
      "442:\tlearn: -0.6364185\ttotal: 5m 47s\tremaining: 7m 17s\n",
      "443:\tlearn: -0.6362579\ttotal: 5m 48s\tremaining: 7m 16s\n",
      "444:\tlearn: -0.6360248\ttotal: 5m 49s\tremaining: 7m 15s\n",
      "445:\tlearn: -0.6356856\ttotal: 5m 50s\tremaining: 7m 15s\n",
      "446:\tlearn: -0.6355330\ttotal: 5m 50s\tremaining: 7m 14s\n",
      "447:\tlearn: -0.6352015\ttotal: 5m 51s\tremaining: 7m 13s\n",
      "448:\tlearn: -0.6348213\ttotal: 5m 52s\tremaining: 7m 12s\n",
      "449:\tlearn: -0.6347042\ttotal: 5m 53s\tremaining: 7m 11s\n",
      "450:\tlearn: -0.6344057\ttotal: 5m 53s\tremaining: 7m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451:\tlearn: -0.6338896\ttotal: 5m 54s\tremaining: 7m 10s\n",
      "452:\tlearn: -0.6336256\ttotal: 5m 55s\tremaining: 7m 9s\n",
      "453:\tlearn: -0.6332804\ttotal: 5m 56s\tremaining: 7m 8s\n",
      "454:\tlearn: -0.6330085\ttotal: 5m 56s\tremaining: 7m 7s\n",
      "455:\tlearn: -0.6326395\ttotal: 5m 57s\tremaining: 7m 6s\n",
      "456:\tlearn: -0.6323304\ttotal: 5m 58s\tremaining: 7m 6s\n",
      "457:\tlearn: -0.6320875\ttotal: 5m 59s\tremaining: 7m 5s\n",
      "458:\tlearn: -0.6316599\ttotal: 6m\tremaining: 7m 4s\n",
      "459:\tlearn: -0.6314393\ttotal: 6m\tremaining: 7m 3s\n",
      "460:\tlearn: -0.6311815\ttotal: 6m 1s\tremaining: 7m 2s\n",
      "461:\tlearn: -0.6308661\ttotal: 6m 2s\tremaining: 7m 2s\n",
      "462:\tlearn: -0.6306996\ttotal: 6m 3s\tremaining: 7m 1s\n",
      "463:\tlearn: -0.6304800\ttotal: 6m 4s\tremaining: 7m\n",
      "464:\tlearn: -0.6302869\ttotal: 6m 4s\tremaining: 6m 59s\n",
      "465:\tlearn: -0.6300134\ttotal: 6m 5s\tremaining: 6m 58s\n",
      "466:\tlearn: -0.6295642\ttotal: 6m 6s\tremaining: 6m 57s\n",
      "467:\tlearn: -0.6292115\ttotal: 6m 6s\tremaining: 6m 57s\n",
      "468:\tlearn: -0.6289792\ttotal: 6m 7s\tremaining: 6m 56s\n",
      "469:\tlearn: -0.6286304\ttotal: 6m 8s\tremaining: 6m 55s\n",
      "470:\tlearn: -0.6282658\ttotal: 6m 9s\tremaining: 6m 54s\n",
      "471:\tlearn: -0.6280645\ttotal: 6m 10s\tremaining: 6m 53s\n",
      "472:\tlearn: -0.6278208\ttotal: 6m 10s\tremaining: 6m 53s\n",
      "473:\tlearn: -0.6274840\ttotal: 6m 11s\tremaining: 6m 52s\n",
      "474:\tlearn: -0.6273847\ttotal: 6m 12s\tremaining: 6m 51s\n",
      "475:\tlearn: -0.6272161\ttotal: 6m 12s\tremaining: 6m 50s\n",
      "476:\tlearn: -0.6270272\ttotal: 6m 13s\tremaining: 6m 49s\n",
      "477:\tlearn: -0.6267036\ttotal: 6m 14s\tremaining: 6m 48s\n",
      "478:\tlearn: -0.6263267\ttotal: 6m 15s\tremaining: 6m 48s\n",
      "479:\tlearn: -0.6260792\ttotal: 6m 16s\tremaining: 6m 47s\n",
      "480:\tlearn: -0.6257828\ttotal: 6m 16s\tremaining: 6m 46s\n",
      "481:\tlearn: -0.6254520\ttotal: 6m 17s\tremaining: 6m 45s\n",
      "482:\tlearn: -0.6252578\ttotal: 6m 18s\tremaining: 6m 44s\n",
      "483:\tlearn: -0.6249914\ttotal: 6m 19s\tremaining: 6m 44s\n",
      "484:\tlearn: -0.6246648\ttotal: 6m 19s\tremaining: 6m 43s\n",
      "485:\tlearn: -0.6243972\ttotal: 6m 20s\tremaining: 6m 42s\n",
      "486:\tlearn: -0.6241274\ttotal: 6m 21s\tremaining: 6m 41s\n",
      "487:\tlearn: -0.6239898\ttotal: 6m 22s\tremaining: 6m 40s\n",
      "488:\tlearn: -0.6237582\ttotal: 6m 22s\tremaining: 6m 39s\n",
      "489:\tlearn: -0.6236490\ttotal: 6m 23s\tremaining: 6m 39s\n",
      "490:\tlearn: -0.6233237\ttotal: 6m 24s\tremaining: 6m 38s\n",
      "491:\tlearn: -0.6230445\ttotal: 6m 24s\tremaining: 6m 37s\n",
      "492:\tlearn: -0.6226796\ttotal: 6m 25s\tremaining: 6m 36s\n",
      "493:\tlearn: -0.6224282\ttotal: 6m 26s\tremaining: 6m 35s\n",
      "494:\tlearn: -0.6221588\ttotal: 6m 27s\tremaining: 6m 35s\n",
      "495:\tlearn: -0.6217536\ttotal: 6m 27s\tremaining: 6m 34s\n",
      "496:\tlearn: -0.6213346\ttotal: 6m 28s\tremaining: 6m 33s\n",
      "497:\tlearn: -0.6210543\ttotal: 6m 29s\tremaining: 6m 32s\n",
      "498:\tlearn: -0.6208679\ttotal: 6m 30s\tremaining: 6m 32s\n",
      "499:\tlearn: -0.6207007\ttotal: 6m 31s\tremaining: 6m 31s\n",
      "500:\tlearn: -0.6205129\ttotal: 6m 32s\tremaining: 6m 30s\n",
      "501:\tlearn: -0.6201449\ttotal: 6m 32s\tremaining: 6m 29s\n",
      "502:\tlearn: -0.6197208\ttotal: 6m 33s\tremaining: 6m 28s\n",
      "503:\tlearn: -0.6194106\ttotal: 6m 34s\tremaining: 6m 28s\n",
      "504:\tlearn: -0.6192881\ttotal: 6m 35s\tremaining: 6m 27s\n",
      "505:\tlearn: -0.6187712\ttotal: 6m 35s\tremaining: 6m 26s\n",
      "506:\tlearn: -0.6184780\ttotal: 6m 36s\tremaining: 6m 25s\n",
      "507:\tlearn: -0.6182766\ttotal: 6m 37s\tremaining: 6m 24s\n",
      "508:\tlearn: -0.6179058\ttotal: 6m 38s\tremaining: 6m 24s\n",
      "509:\tlearn: -0.6177023\ttotal: 6m 38s\tremaining: 6m 23s\n",
      "510:\tlearn: -0.6171025\ttotal: 6m 39s\tremaining: 6m 22s\n",
      "511:\tlearn: -0.6167367\ttotal: 6m 40s\tremaining: 6m 21s\n",
      "512:\tlearn: -0.6165753\ttotal: 6m 41s\tremaining: 6m 20s\n",
      "513:\tlearn: -0.6164169\ttotal: 6m 42s\tremaining: 6m 20s\n",
      "514:\tlearn: -0.6159609\ttotal: 6m 42s\tremaining: 6m 19s\n",
      "515:\tlearn: -0.6156753\ttotal: 6m 43s\tremaining: 6m 18s\n",
      "516:\tlearn: -0.6153068\ttotal: 6m 44s\tremaining: 6m 17s\n",
      "517:\tlearn: -0.6150461\ttotal: 6m 45s\tremaining: 6m 17s\n",
      "518:\tlearn: -0.6147070\ttotal: 6m 46s\tremaining: 6m 16s\n",
      "519:\tlearn: -0.6144378\ttotal: 6m 46s\tremaining: 6m 15s\n",
      "520:\tlearn: -0.6143204\ttotal: 6m 47s\tremaining: 6m 14s\n",
      "521:\tlearn: -0.6140663\ttotal: 6m 48s\tremaining: 6m 13s\n",
      "522:\tlearn: -0.6139263\ttotal: 6m 49s\tremaining: 6m 13s\n",
      "523:\tlearn: -0.6137643\ttotal: 6m 49s\tremaining: 6m 12s\n",
      "524:\tlearn: -0.6135753\ttotal: 6m 50s\tremaining: 6m 11s\n",
      "525:\tlearn: -0.6132676\ttotal: 6m 51s\tremaining: 6m 10s\n",
      "526:\tlearn: -0.6128803\ttotal: 6m 52s\tremaining: 6m 10s\n",
      "527:\tlearn: -0.6126935\ttotal: 6m 53s\tremaining: 6m 9s\n",
      "528:\tlearn: -0.6123852\ttotal: 6m 53s\tremaining: 6m 8s\n",
      "529:\tlearn: -0.6121035\ttotal: 6m 54s\tremaining: 6m 7s\n",
      "530:\tlearn: -0.6117041\ttotal: 6m 55s\tremaining: 6m 6s\n",
      "531:\tlearn: -0.6114582\ttotal: 6m 56s\tremaining: 6m 6s\n",
      "532:\tlearn: -0.6111537\ttotal: 6m 56s\tremaining: 6m 5s\n",
      "533:\tlearn: -0.6109407\ttotal: 6m 57s\tremaining: 6m 4s\n",
      "534:\tlearn: -0.6107481\ttotal: 6m 58s\tremaining: 6m 3s\n",
      "535:\tlearn: -0.6103264\ttotal: 6m 59s\tremaining: 6m 2s\n",
      "536:\tlearn: -0.6101136\ttotal: 6m 59s\tremaining: 6m 2s\n",
      "537:\tlearn: -0.6097361\ttotal: 7m\tremaining: 6m 1s\n",
      "538:\tlearn: -0.6095143\ttotal: 7m 1s\tremaining: 6m\n",
      "539:\tlearn: -0.6093869\ttotal: 7m 2s\tremaining: 5m 59s\n",
      "540:\tlearn: -0.6092242\ttotal: 7m 2s\tremaining: 5m 58s\n",
      "541:\tlearn: -0.6089775\ttotal: 7m 3s\tremaining: 5m 58s\n",
      "542:\tlearn: -0.6087315\ttotal: 7m 4s\tremaining: 5m 57s\n",
      "543:\tlearn: -0.6085286\ttotal: 7m 5s\tremaining: 5m 56s\n",
      "544:\tlearn: -0.6084291\ttotal: 7m 5s\tremaining: 5m 55s\n",
      "545:\tlearn: -0.6081834\ttotal: 7m 6s\tremaining: 5m 54s\n",
      "546:\tlearn: -0.6077847\ttotal: 7m 7s\tremaining: 5m 53s\n",
      "547:\tlearn: -0.6076495\ttotal: 7m 8s\tremaining: 5m 53s\n",
      "548:\tlearn: -0.6074610\ttotal: 7m 8s\tremaining: 5m 52s\n",
      "549:\tlearn: -0.6070735\ttotal: 7m 9s\tremaining: 5m 51s\n",
      "550:\tlearn: -0.6068058\ttotal: 7m 10s\tremaining: 5m 50s\n",
      "551:\tlearn: -0.6063333\ttotal: 7m 11s\tremaining: 5m 50s\n",
      "552:\tlearn: -0.6060856\ttotal: 7m 12s\tremaining: 5m 49s\n",
      "553:\tlearn: -0.6059699\ttotal: 7m 12s\tremaining: 5m 48s\n",
      "554:\tlearn: -0.6055801\ttotal: 7m 13s\tremaining: 5m 47s\n",
      "555:\tlearn: -0.6054030\ttotal: 7m 14s\tremaining: 5m 46s\n",
      "556:\tlearn: -0.6052248\ttotal: 7m 15s\tremaining: 5m 46s\n",
      "557:\tlearn: -0.6050741\ttotal: 7m 16s\tremaining: 5m 45s\n",
      "558:\tlearn: -0.6047948\ttotal: 7m 16s\tremaining: 5m 44s\n",
      "559:\tlearn: -0.6046008\ttotal: 7m 17s\tremaining: 5m 43s\n",
      "560:\tlearn: -0.6044491\ttotal: 7m 18s\tremaining: 5m 43s\n",
      "561:\tlearn: -0.6042061\ttotal: 7m 19s\tremaining: 5m 42s\n",
      "562:\tlearn: -0.6039806\ttotal: 7m 20s\tremaining: 5m 41s\n",
      "563:\tlearn: -0.6036176\ttotal: 7m 20s\tremaining: 5m 40s\n",
      "564:\tlearn: -0.6032262\ttotal: 7m 21s\tremaining: 5m 40s\n",
      "565:\tlearn: -0.6028846\ttotal: 7m 22s\tremaining: 5m 39s\n",
      "566:\tlearn: -0.6024433\ttotal: 7m 23s\tremaining: 5m 38s\n",
      "567:\tlearn: -0.6022624\ttotal: 7m 24s\tremaining: 5m 37s\n",
      "568:\tlearn: -0.6019878\ttotal: 7m 24s\tremaining: 5m 36s\n",
      "569:\tlearn: -0.6018327\ttotal: 7m 25s\tremaining: 5m 36s\n",
      "570:\tlearn: -0.6015757\ttotal: 7m 26s\tremaining: 5m 35s\n",
      "571:\tlearn: -0.6012010\ttotal: 7m 27s\tremaining: 5m 34s\n",
      "572:\tlearn: -0.6010678\ttotal: 7m 28s\tremaining: 5m 33s\n",
      "573:\tlearn: -0.6006727\ttotal: 7m 28s\tremaining: 5m 33s\n",
      "574:\tlearn: -0.6004258\ttotal: 7m 29s\tremaining: 5m 32s\n",
      "575:\tlearn: -0.6003351\ttotal: 7m 30s\tremaining: 5m 31s\n",
      "576:\tlearn: -0.5998963\ttotal: 7m 31s\tremaining: 5m 30s\n",
      "577:\tlearn: -0.5996931\ttotal: 7m 31s\tremaining: 5m 29s\n",
      "578:\tlearn: -0.5994952\ttotal: 7m 32s\tremaining: 5m 29s\n",
      "579:\tlearn: -0.5993208\ttotal: 7m 33s\tremaining: 5m 28s\n",
      "580:\tlearn: -0.5989441\ttotal: 7m 34s\tremaining: 5m 27s\n",
      "581:\tlearn: -0.5987223\ttotal: 7m 35s\tremaining: 5m 26s\n",
      "582:\tlearn: -0.5984446\ttotal: 7m 35s\tremaining: 5m 26s\n",
      "583:\tlearn: -0.5981141\ttotal: 7m 36s\tremaining: 5m 25s\n",
      "584:\tlearn: -0.5978132\ttotal: 7m 37s\tremaining: 5m 24s\n",
      "585:\tlearn: -0.5975851\ttotal: 7m 38s\tremaining: 5m 23s\n",
      "586:\tlearn: -0.5973610\ttotal: 7m 38s\tremaining: 5m 22s\n",
      "587:\tlearn: -0.5971990\ttotal: 7m 39s\tremaining: 5m 22s\n",
      "588:\tlearn: -0.5968450\ttotal: 7m 40s\tremaining: 5m 21s\n",
      "589:\tlearn: -0.5965992\ttotal: 7m 41s\tremaining: 5m 20s\n",
      "590:\tlearn: -0.5963218\ttotal: 7m 41s\tremaining: 5m 19s\n",
      "591:\tlearn: -0.5959305\ttotal: 7m 42s\tremaining: 5m 18s\n",
      "592:\tlearn: -0.5956452\ttotal: 7m 43s\tremaining: 5m 18s\n",
      "593:\tlearn: -0.5955300\ttotal: 7m 44s\tremaining: 5m 17s\n",
      "594:\tlearn: -0.5952190\ttotal: 7m 44s\tremaining: 5m 16s\n",
      "595:\tlearn: -0.5951274\ttotal: 7m 45s\tremaining: 5m 15s\n",
      "596:\tlearn: -0.5949871\ttotal: 7m 46s\tremaining: 5m 14s\n",
      "597:\tlearn: -0.5947737\ttotal: 7m 46s\tremaining: 5m 13s\n",
      "598:\tlearn: -0.5945834\ttotal: 7m 47s\tremaining: 5m 13s\n",
      "599:\tlearn: -0.5942615\ttotal: 7m 48s\tremaining: 5m 12s\n",
      "600:\tlearn: -0.5940728\ttotal: 7m 49s\tremaining: 5m 11s\n",
      "601:\tlearn: -0.5938579\ttotal: 7m 49s\tremaining: 5m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602:\tlearn: -0.5935462\ttotal: 7m 50s\tremaining: 5m 9s\n",
      "603:\tlearn: -0.5933418\ttotal: 7m 51s\tremaining: 5m 9s\n",
      "604:\tlearn: -0.5931733\ttotal: 7m 52s\tremaining: 5m 8s\n",
      "605:\tlearn: -0.5930420\ttotal: 7m 52s\tremaining: 5m 7s\n",
      "606:\tlearn: -0.5928002\ttotal: 7m 53s\tremaining: 5m 6s\n",
      "607:\tlearn: -0.5925573\ttotal: 7m 54s\tremaining: 5m 5s\n",
      "608:\tlearn: -0.5923912\ttotal: 7m 55s\tremaining: 5m 5s\n",
      "609:\tlearn: -0.5919459\ttotal: 7m 56s\tremaining: 5m 4s\n",
      "610:\tlearn: -0.5916940\ttotal: 7m 56s\tremaining: 5m 3s\n",
      "611:\tlearn: -0.5914604\ttotal: 7m 57s\tremaining: 5m 2s\n",
      "612:\tlearn: -0.5911016\ttotal: 7m 58s\tremaining: 5m 1s\n",
      "613:\tlearn: -0.5910088\ttotal: 7m 58s\tremaining: 5m 1s\n",
      "614:\tlearn: -0.5908223\ttotal: 7m 59s\tremaining: 5m\n",
      "615:\tlearn: -0.5904554\ttotal: 8m\tremaining: 4m 59s\n",
      "616:\tlearn: -0.5901429\ttotal: 8m 1s\tremaining: 4m 58s\n",
      "617:\tlearn: -0.5899240\ttotal: 8m 1s\tremaining: 4m 57s\n",
      "618:\tlearn: -0.5896723\ttotal: 8m 2s\tremaining: 4m 57s\n",
      "619:\tlearn: -0.5894237\ttotal: 8m 3s\tremaining: 4m 56s\n",
      "620:\tlearn: -0.5892185\ttotal: 8m 4s\tremaining: 4m 55s\n",
      "621:\tlearn: -0.5890670\ttotal: 8m 4s\tremaining: 4m 54s\n",
      "622:\tlearn: -0.5887539\ttotal: 8m 5s\tremaining: 4m 53s\n",
      "623:\tlearn: -0.5882159\ttotal: 8m 6s\tremaining: 4m 53s\n",
      "624:\tlearn: -0.5880328\ttotal: 8m 7s\tremaining: 4m 52s\n",
      "625:\tlearn: -0.5877119\ttotal: 8m 8s\tremaining: 4m 51s\n",
      "626:\tlearn: -0.5875477\ttotal: 8m 8s\tremaining: 4m 50s\n",
      "627:\tlearn: -0.5873808\ttotal: 8m 9s\tremaining: 4m 50s\n",
      "628:\tlearn: -0.5870385\ttotal: 8m 10s\tremaining: 4m 49s\n",
      "629:\tlearn: -0.5867916\ttotal: 8m 11s\tremaining: 4m 48s\n",
      "630:\tlearn: -0.5865631\ttotal: 8m 11s\tremaining: 4m 47s\n",
      "631:\tlearn: -0.5863282\ttotal: 8m 12s\tremaining: 4m 46s\n",
      "632:\tlearn: -0.5859692\ttotal: 8m 13s\tremaining: 4m 46s\n",
      "633:\tlearn: -0.5857335\ttotal: 8m 14s\tremaining: 4m 45s\n",
      "634:\tlearn: -0.5855986\ttotal: 8m 14s\tremaining: 4m 44s\n",
      "635:\tlearn: -0.5852826\ttotal: 8m 15s\tremaining: 4m 43s\n",
      "636:\tlearn: -0.5850179\ttotal: 8m 16s\tremaining: 4m 42s\n",
      "637:\tlearn: -0.5847743\ttotal: 8m 17s\tremaining: 4m 42s\n",
      "638:\tlearn: -0.5846337\ttotal: 8m 17s\tremaining: 4m 41s\n",
      "639:\tlearn: -0.5844051\ttotal: 8m 18s\tremaining: 4m 40s\n",
      "640:\tlearn: -0.5841908\ttotal: 8m 19s\tremaining: 4m 39s\n",
      "641:\tlearn: -0.5840354\ttotal: 8m 20s\tremaining: 4m 38s\n",
      "642:\tlearn: -0.5838601\ttotal: 8m 20s\tremaining: 4m 38s\n",
      "643:\tlearn: -0.5837515\ttotal: 8m 21s\tremaining: 4m 37s\n",
      "644:\tlearn: -0.5836455\ttotal: 8m 22s\tremaining: 4m 36s\n",
      "645:\tlearn: -0.5834178\ttotal: 8m 23s\tremaining: 4m 35s\n",
      "646:\tlearn: -0.5831110\ttotal: 8m 23s\tremaining: 4m 34s\n",
      "647:\tlearn: -0.5828954\ttotal: 8m 24s\tremaining: 4m 34s\n",
      "648:\tlearn: -0.5825511\ttotal: 8m 25s\tremaining: 4m 33s\n",
      "649:\tlearn: -0.5821408\ttotal: 8m 26s\tremaining: 4m 32s\n",
      "650:\tlearn: -0.5820444\ttotal: 8m 26s\tremaining: 4m 31s\n",
      "651:\tlearn: -0.5817574\ttotal: 8m 27s\tremaining: 4m 31s\n",
      "652:\tlearn: -0.5814034\ttotal: 8m 28s\tremaining: 4m 30s\n",
      "653:\tlearn: -0.5812774\ttotal: 8m 29s\tremaining: 4m 29s\n",
      "654:\tlearn: -0.5809739\ttotal: 8m 30s\tremaining: 4m 28s\n",
      "655:\tlearn: -0.5806632\ttotal: 8m 30s\tremaining: 4m 27s\n",
      "656:\tlearn: -0.5804993\ttotal: 8m 31s\tremaining: 4m 27s\n",
      "657:\tlearn: -0.5803177\ttotal: 8m 32s\tremaining: 4m 26s\n",
      "658:\tlearn: -0.5801288\ttotal: 8m 33s\tremaining: 4m 25s\n",
      "659:\tlearn: -0.5799307\ttotal: 8m 33s\tremaining: 4m 24s\n",
      "660:\tlearn: -0.5797405\ttotal: 8m 34s\tremaining: 4m 23s\n",
      "661:\tlearn: -0.5794827\ttotal: 8m 35s\tremaining: 4m 23s\n",
      "662:\tlearn: -0.5793083\ttotal: 8m 36s\tremaining: 4m 22s\n",
      "663:\tlearn: -0.5789906\ttotal: 8m 36s\tremaining: 4m 21s\n",
      "664:\tlearn: -0.5787257\ttotal: 8m 37s\tremaining: 4m 20s\n",
      "665:\tlearn: -0.5785403\ttotal: 8m 38s\tremaining: 4m 19s\n",
      "666:\tlearn: -0.5779988\ttotal: 8m 38s\tremaining: 4m 19s\n",
      "667:\tlearn: -0.5777949\ttotal: 8m 39s\tremaining: 4m 18s\n",
      "668:\tlearn: -0.5775184\ttotal: 8m 39s\tremaining: 4m 17s\n",
      "669:\tlearn: -0.5772665\ttotal: 8m 40s\tremaining: 4m 16s\n",
      "670:\tlearn: -0.5770060\ttotal: 8m 40s\tremaining: 4m 15s\n",
      "671:\tlearn: -0.5769220\ttotal: 8m 41s\tremaining: 4m 14s\n",
      "672:\tlearn: -0.5766230\ttotal: 8m 41s\tremaining: 4m 13s\n",
      "673:\tlearn: -0.5764078\ttotal: 8m 42s\tremaining: 4m 12s\n",
      "674:\tlearn: -0.5761618\ttotal: 8m 42s\tremaining: 4m 11s\n",
      "675:\tlearn: -0.5760351\ttotal: 8m 43s\tremaining: 4m 10s\n",
      "676:\tlearn: -0.5757897\ttotal: 8m 43s\tremaining: 4m 9s\n",
      "677:\tlearn: -0.5754883\ttotal: 8m 43s\tremaining: 4m 8s\n",
      "678:\tlearn: -0.5751362\ttotal: 8m 44s\tremaining: 4m 7s\n",
      "679:\tlearn: -0.5750010\ttotal: 8m 44s\tremaining: 4m 6s\n",
      "680:\tlearn: -0.5748733\ttotal: 8m 45s\tremaining: 4m 5s\n",
      "681:\tlearn: -0.5746553\ttotal: 8m 45s\tremaining: 4m 5s\n",
      "682:\tlearn: -0.5744587\ttotal: 8m 45s\tremaining: 4m 4s\n",
      "683:\tlearn: -0.5740761\ttotal: 8m 46s\tremaining: 4m 3s\n",
      "684:\tlearn: -0.5739554\ttotal: 8m 46s\tremaining: 4m 2s\n",
      "685:\tlearn: -0.5737469\ttotal: 8m 47s\tremaining: 4m 1s\n",
      "686:\tlearn: -0.5734533\ttotal: 8m 47s\tremaining: 4m\n",
      "687:\tlearn: -0.5730770\ttotal: 8m 47s\tremaining: 3m 59s\n",
      "688:\tlearn: -0.5728589\ttotal: 8m 48s\tremaining: 3m 58s\n",
      "689:\tlearn: -0.5727259\ttotal: 8m 48s\tremaining: 3m 57s\n",
      "690:\tlearn: -0.5725437\ttotal: 8m 49s\tremaining: 3m 56s\n",
      "691:\tlearn: -0.5722204\ttotal: 8m 49s\tremaining: 3m 55s\n",
      "692:\tlearn: -0.5719620\ttotal: 8m 50s\tremaining: 3m 54s\n",
      "693:\tlearn: -0.5717780\ttotal: 8m 50s\tremaining: 3m 53s\n",
      "694:\tlearn: -0.5715048\ttotal: 8m 50s\tremaining: 3m 52s\n",
      "695:\tlearn: -0.5713425\ttotal: 8m 51s\tremaining: 3m 52s\n",
      "696:\tlearn: -0.5711301\ttotal: 8m 51s\tremaining: 3m 51s\n",
      "697:\tlearn: -0.5707372\ttotal: 8m 52s\tremaining: 3m 50s\n",
      "698:\tlearn: -0.5704784\ttotal: 8m 52s\tremaining: 3m 49s\n",
      "699:\tlearn: -0.5703322\ttotal: 8m 52s\tremaining: 3m 48s\n",
      "700:\tlearn: -0.5700133\ttotal: 8m 53s\tremaining: 3m 47s\n",
      "701:\tlearn: -0.5696214\ttotal: 8m 53s\tremaining: 3m 46s\n",
      "702:\tlearn: -0.5695065\ttotal: 8m 54s\tremaining: 3m 45s\n",
      "703:\tlearn: -0.5693918\ttotal: 8m 54s\tremaining: 3m 44s\n",
      "704:\tlearn: -0.5692803\ttotal: 8m 55s\tremaining: 3m 43s\n",
      "705:\tlearn: -0.5691552\ttotal: 8m 55s\tremaining: 3m 42s\n",
      "706:\tlearn: -0.5689360\ttotal: 8m 55s\tremaining: 3m 42s\n",
      "707:\tlearn: -0.5687825\ttotal: 8m 56s\tremaining: 3m 41s\n",
      "708:\tlearn: -0.5685913\ttotal: 8m 56s\tremaining: 3m 40s\n",
      "709:\tlearn: -0.5683954\ttotal: 8m 57s\tremaining: 3m 39s\n",
      "710:\tlearn: -0.5681064\ttotal: 8m 57s\tremaining: 3m 38s\n",
      "711:\tlearn: -0.5679254\ttotal: 8m 57s\tremaining: 3m 37s\n",
      "712:\tlearn: -0.5676838\ttotal: 8m 58s\tremaining: 3m 36s\n",
      "713:\tlearn: -0.5674431\ttotal: 8m 58s\tremaining: 3m 35s\n",
      "714:\tlearn: -0.5673452\ttotal: 8m 59s\tremaining: 3m 34s\n",
      "715:\tlearn: -0.5671560\ttotal: 8m 59s\tremaining: 3m 34s\n",
      "716:\tlearn: -0.5669666\ttotal: 8m 59s\tremaining: 3m 33s\n",
      "717:\tlearn: -0.5667365\ttotal: 9m\tremaining: 3m 32s\n",
      "718:\tlearn: -0.5664422\ttotal: 9m\tremaining: 3m 31s\n",
      "719:\tlearn: -0.5661921\ttotal: 9m 1s\tremaining: 3m 30s\n",
      "720:\tlearn: -0.5659788\ttotal: 9m 1s\tremaining: 3m 29s\n",
      "721:\tlearn: -0.5657232\ttotal: 9m 2s\tremaining: 3m 28s\n",
      "722:\tlearn: -0.5655035\ttotal: 9m 2s\tremaining: 3m 27s\n",
      "723:\tlearn: -0.5652963\ttotal: 9m 2s\tremaining: 3m 26s\n",
      "724:\tlearn: -0.5649520\ttotal: 9m 3s\tremaining: 3m 26s\n",
      "725:\tlearn: -0.5647556\ttotal: 9m 3s\tremaining: 3m 25s\n",
      "726:\tlearn: -0.5644747\ttotal: 9m 4s\tremaining: 3m 24s\n",
      "727:\tlearn: -0.5641272\ttotal: 9m 4s\tremaining: 3m 23s\n",
      "728:\tlearn: -0.5637582\ttotal: 9m 5s\tremaining: 3m 22s\n",
      "729:\tlearn: -0.5636363\ttotal: 9m 5s\tremaining: 3m 21s\n",
      "730:\tlearn: -0.5633398\ttotal: 9m 5s\tremaining: 3m 20s\n",
      "731:\tlearn: -0.5629635\ttotal: 9m 6s\tremaining: 3m 20s\n",
      "732:\tlearn: -0.5627840\ttotal: 9m 6s\tremaining: 3m 19s\n",
      "733:\tlearn: -0.5624460\ttotal: 9m 7s\tremaining: 3m 18s\n",
      "734:\tlearn: -0.5623603\ttotal: 9m 7s\tremaining: 3m 17s\n",
      "735:\tlearn: -0.5620917\ttotal: 9m 7s\tremaining: 3m 16s\n",
      "736:\tlearn: -0.5618578\ttotal: 9m 8s\tremaining: 3m 15s\n",
      "737:\tlearn: -0.5617674\ttotal: 9m 8s\tremaining: 3m 14s\n",
      "738:\tlearn: -0.5616591\ttotal: 9m 9s\tremaining: 3m 13s\n",
      "739:\tlearn: -0.5615288\ttotal: 9m 9s\tremaining: 3m 13s\n",
      "740:\tlearn: -0.5614471\ttotal: 9m 9s\tremaining: 3m 12s\n",
      "741:\tlearn: -0.5613419\ttotal: 9m 10s\tremaining: 3m 11s\n",
      "742:\tlearn: -0.5611647\ttotal: 9m 10s\tremaining: 3m 10s\n",
      "743:\tlearn: -0.5609419\ttotal: 9m 11s\tremaining: 3m 9s\n",
      "744:\tlearn: -0.5607993\ttotal: 9m 11s\tremaining: 3m 8s\n",
      "745:\tlearn: -0.5606118\ttotal: 9m 12s\tremaining: 3m 7s\n",
      "746:\tlearn: -0.5603570\ttotal: 9m 12s\tremaining: 3m 7s\n",
      "747:\tlearn: -0.5602153\ttotal: 9m 12s\tremaining: 3m 6s\n",
      "748:\tlearn: -0.5600346\ttotal: 9m 13s\tremaining: 3m 5s\n",
      "749:\tlearn: -0.5598596\ttotal: 9m 13s\tremaining: 3m 4s\n",
      "750:\tlearn: -0.5596766\ttotal: 9m 14s\tremaining: 3m 3s\n",
      "751:\tlearn: -0.5595257\ttotal: 9m 14s\tremaining: 3m 2s\n",
      "752:\tlearn: -0.5589814\ttotal: 9m 14s\tremaining: 3m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753:\tlearn: -0.5588255\ttotal: 9m 15s\tremaining: 3m 1s\n",
      "754:\tlearn: -0.5587085\ttotal: 9m 15s\tremaining: 3m\n",
      "755:\tlearn: -0.5585457\ttotal: 9m 16s\tremaining: 2m 59s\n",
      "756:\tlearn: -0.5582185\ttotal: 9m 16s\tremaining: 2m 58s\n",
      "757:\tlearn: -0.5580793\ttotal: 9m 17s\tremaining: 2m 57s\n",
      "758:\tlearn: -0.5579070\ttotal: 9m 17s\tremaining: 2m 56s\n",
      "759:\tlearn: -0.5576614\ttotal: 9m 17s\tremaining: 2m 56s\n",
      "760:\tlearn: -0.5575167\ttotal: 9m 18s\tremaining: 2m 55s\n",
      "761:\tlearn: -0.5572865\ttotal: 9m 18s\tremaining: 2m 54s\n",
      "762:\tlearn: -0.5569624\ttotal: 9m 19s\tremaining: 2m 53s\n",
      "763:\tlearn: -0.5568412\ttotal: 9m 19s\tremaining: 2m 52s\n",
      "764:\tlearn: -0.5564913\ttotal: 9m 19s\tremaining: 2m 52s\n",
      "765:\tlearn: -0.5563241\ttotal: 9m 20s\tremaining: 2m 51s\n",
      "766:\tlearn: -0.5560219\ttotal: 9m 20s\tremaining: 2m 50s\n",
      "767:\tlearn: -0.5557174\ttotal: 9m 21s\tremaining: 2m 49s\n",
      "768:\tlearn: -0.5554848\ttotal: 9m 21s\tremaining: 2m 48s\n",
      "769:\tlearn: -0.5553950\ttotal: 9m 22s\tremaining: 2m 47s\n",
      "770:\tlearn: -0.5550680\ttotal: 9m 22s\tremaining: 2m 47s\n",
      "771:\tlearn: -0.5549362\ttotal: 9m 22s\tremaining: 2m 46s\n",
      "772:\tlearn: -0.5546278\ttotal: 9m 23s\tremaining: 2m 45s\n",
      "773:\tlearn: -0.5544782\ttotal: 9m 23s\tremaining: 2m 44s\n",
      "774:\tlearn: -0.5543685\ttotal: 9m 24s\tremaining: 2m 43s\n",
      "775:\tlearn: -0.5542035\ttotal: 9m 24s\tremaining: 2m 42s\n",
      "776:\tlearn: -0.5538122\ttotal: 9m 25s\tremaining: 2m 42s\n",
      "777:\tlearn: -0.5534559\ttotal: 9m 25s\tremaining: 2m 41s\n",
      "778:\tlearn: -0.5531302\ttotal: 9m 25s\tremaining: 2m 40s\n",
      "779:\tlearn: -0.5529217\ttotal: 9m 26s\tremaining: 2m 39s\n",
      "780:\tlearn: -0.5527681\ttotal: 9m 26s\tremaining: 2m 38s\n",
      "781:\tlearn: -0.5525582\ttotal: 9m 27s\tremaining: 2m 38s\n",
      "782:\tlearn: -0.5522970\ttotal: 9m 27s\tremaining: 2m 37s\n",
      "783:\tlearn: -0.5521086\ttotal: 9m 27s\tremaining: 2m 36s\n",
      "784:\tlearn: -0.5518692\ttotal: 9m 28s\tremaining: 2m 35s\n",
      "785:\tlearn: -0.5515083\ttotal: 9m 28s\tremaining: 2m 34s\n",
      "786:\tlearn: -0.5511741\ttotal: 9m 29s\tremaining: 2m 34s\n",
      "787:\tlearn: -0.5507302\ttotal: 9m 29s\tremaining: 2m 33s\n",
      "788:\tlearn: -0.5504508\ttotal: 9m 30s\tremaining: 2m 32s\n",
      "789:\tlearn: -0.5502231\ttotal: 9m 30s\tremaining: 2m 31s\n",
      "790:\tlearn: -0.5500765\ttotal: 9m 30s\tremaining: 2m 30s\n",
      "791:\tlearn: -0.5499597\ttotal: 9m 31s\tremaining: 2m 30s\n",
      "792:\tlearn: -0.5497547\ttotal: 9m 31s\tremaining: 2m 29s\n",
      "793:\tlearn: -0.5495697\ttotal: 9m 32s\tremaining: 2m 28s\n",
      "794:\tlearn: -0.5493450\ttotal: 9m 32s\tremaining: 2m 27s\n",
      "795:\tlearn: -0.5490114\ttotal: 9m 32s\tremaining: 2m 26s\n",
      "796:\tlearn: -0.5486324\ttotal: 9m 33s\tremaining: 2m 26s\n",
      "797:\tlearn: -0.5483761\ttotal: 9m 33s\tremaining: 2m 25s\n",
      "798:\tlearn: -0.5480656\ttotal: 9m 34s\tremaining: 2m 24s\n",
      "799:\tlearn: -0.5477811\ttotal: 9m 34s\tremaining: 2m 23s\n",
      "800:\tlearn: -0.5475374\ttotal: 9m 35s\tremaining: 2m 22s\n",
      "801:\tlearn: -0.5472873\ttotal: 9m 35s\tremaining: 2m 22s\n",
      "802:\tlearn: -0.5469173\ttotal: 9m 35s\tremaining: 2m 21s\n",
      "803:\tlearn: -0.5467908\ttotal: 9m 36s\tremaining: 2m 20s\n",
      "804:\tlearn: -0.5466458\ttotal: 9m 36s\tremaining: 2m 19s\n",
      "805:\tlearn: -0.5465483\ttotal: 9m 37s\tremaining: 2m 18s\n",
      "806:\tlearn: -0.5462444\ttotal: 9m 37s\tremaining: 2m 18s\n",
      "807:\tlearn: -0.5458761\ttotal: 9m 38s\tremaining: 2m 17s\n",
      "808:\tlearn: -0.5455481\ttotal: 9m 38s\tremaining: 2m 16s\n",
      "809:\tlearn: -0.5454175\ttotal: 9m 38s\tremaining: 2m 15s\n",
      "810:\tlearn: -0.5452643\ttotal: 9m 39s\tremaining: 2m 14s\n",
      "811:\tlearn: -0.5450808\ttotal: 9m 39s\tremaining: 2m 14s\n",
      "812:\tlearn: -0.5448890\ttotal: 9m 40s\tremaining: 2m 13s\n",
      "813:\tlearn: -0.5448185\ttotal: 9m 40s\tremaining: 2m 12s\n",
      "814:\tlearn: -0.5446445\ttotal: 9m 40s\tremaining: 2m 11s\n",
      "815:\tlearn: -0.5444892\ttotal: 9m 41s\tremaining: 2m 11s\n",
      "816:\tlearn: -0.5442344\ttotal: 9m 41s\tremaining: 2m 10s\n",
      "817:\tlearn: -0.5441691\ttotal: 9m 42s\tremaining: 2m 9s\n",
      "818:\tlearn: -0.5440079\ttotal: 9m 42s\tremaining: 2m 8s\n",
      "819:\tlearn: -0.5437165\ttotal: 9m 43s\tremaining: 2m 8s\n",
      "820:\tlearn: -0.5434328\ttotal: 9m 43s\tremaining: 2m 7s\n",
      "821:\tlearn: -0.5432704\ttotal: 9m 44s\tremaining: 2m 6s\n",
      "822:\tlearn: -0.5430871\ttotal: 9m 44s\tremaining: 2m 5s\n",
      "823:\tlearn: -0.5428228\ttotal: 9m 44s\tremaining: 2m 4s\n",
      "824:\tlearn: -0.5426067\ttotal: 9m 45s\tremaining: 2m 4s\n",
      "825:\tlearn: -0.5424255\ttotal: 9m 45s\tremaining: 2m 3s\n",
      "826:\tlearn: -0.5421539\ttotal: 9m 46s\tremaining: 2m 2s\n",
      "827:\tlearn: -0.5419365\ttotal: 9m 46s\tremaining: 2m 1s\n",
      "828:\tlearn: -0.5416338\ttotal: 9m 47s\tremaining: 2m 1s\n",
      "829:\tlearn: -0.5414642\ttotal: 9m 47s\tremaining: 2m\n",
      "830:\tlearn: -0.5412435\ttotal: 9m 47s\tremaining: 1m 59s\n",
      "831:\tlearn: -0.5410691\ttotal: 9m 48s\tremaining: 1m 58s\n",
      "832:\tlearn: -0.5409674\ttotal: 9m 48s\tremaining: 1m 58s\n",
      "833:\tlearn: -0.5408311\ttotal: 9m 49s\tremaining: 1m 57s\n",
      "834:\tlearn: -0.5405936\ttotal: 9m 49s\tremaining: 1m 56s\n",
      "835:\tlearn: -0.5402718\ttotal: 9m 50s\tremaining: 1m 55s\n",
      "836:\tlearn: -0.5400430\ttotal: 9m 50s\tremaining: 1m 54s\n",
      "837:\tlearn: -0.5397552\ttotal: 9m 50s\tremaining: 1m 54s\n",
      "838:\tlearn: -0.5395822\ttotal: 9m 51s\tremaining: 1m 53s\n",
      "839:\tlearn: -0.5394361\ttotal: 9m 51s\tremaining: 1m 52s\n",
      "840:\tlearn: -0.5391963\ttotal: 9m 52s\tremaining: 1m 51s\n",
      "841:\tlearn: -0.5389783\ttotal: 9m 52s\tremaining: 1m 51s\n",
      "842:\tlearn: -0.5387627\ttotal: 9m 52s\tremaining: 1m 50s\n",
      "843:\tlearn: -0.5384696\ttotal: 9m 53s\tremaining: 1m 49s\n",
      "844:\tlearn: -0.5382152\ttotal: 9m 53s\tremaining: 1m 48s\n",
      "845:\tlearn: -0.5381265\ttotal: 9m 54s\tremaining: 1m 48s\n",
      "846:\tlearn: -0.5379787\ttotal: 9m 54s\tremaining: 1m 47s\n",
      "847:\tlearn: -0.5378415\ttotal: 9m 55s\tremaining: 1m 46s\n",
      "848:\tlearn: -0.5375972\ttotal: 9m 55s\tremaining: 1m 45s\n",
      "849:\tlearn: -0.5372357\ttotal: 9m 55s\tremaining: 1m 45s\n",
      "850:\tlearn: -0.5370592\ttotal: 9m 56s\tremaining: 1m 44s\n",
      "851:\tlearn: -0.5369191\ttotal: 9m 56s\tremaining: 1m 43s\n",
      "852:\tlearn: -0.5367657\ttotal: 9m 57s\tremaining: 1m 42s\n",
      "853:\tlearn: -0.5366039\ttotal: 9m 57s\tremaining: 1m 42s\n",
      "854:\tlearn: -0.5364682\ttotal: 9m 58s\tremaining: 1m 41s\n",
      "855:\tlearn: -0.5361876\ttotal: 9m 58s\tremaining: 1m 40s\n",
      "856:\tlearn: -0.5360457\ttotal: 9m 59s\tremaining: 1m 40s\n",
      "857:\tlearn: -0.5357784\ttotal: 9m 59s\tremaining: 1m 39s\n",
      "858:\tlearn: -0.5355287\ttotal: 10m\tremaining: 1m 38s\n",
      "859:\tlearn: -0.5354422\ttotal: 10m\tremaining: 1m 37s\n",
      "860:\tlearn: -0.5353492\ttotal: 10m 1s\tremaining: 1m 37s\n",
      "861:\tlearn: -0.5351705\ttotal: 10m 1s\tremaining: 1m 36s\n",
      "862:\tlearn: -0.5350262\ttotal: 10m 1s\tremaining: 1m 35s\n",
      "863:\tlearn: -0.5349027\ttotal: 10m 2s\tremaining: 1m 34s\n",
      "864:\tlearn: -0.5347248\ttotal: 10m 2s\tremaining: 1m 34s\n",
      "865:\tlearn: -0.5344525\ttotal: 10m 3s\tremaining: 1m 33s\n",
      "866:\tlearn: -0.5342782\ttotal: 10m 3s\tremaining: 1m 32s\n",
      "867:\tlearn: -0.5339094\ttotal: 10m 4s\tremaining: 1m 31s\n",
      "868:\tlearn: -0.5335891\ttotal: 10m 4s\tremaining: 1m 31s\n",
      "869:\tlearn: -0.5334558\ttotal: 10m 5s\tremaining: 1m 30s\n",
      "870:\tlearn: -0.5331306\ttotal: 10m 5s\tremaining: 1m 29s\n",
      "871:\tlearn: -0.5330332\ttotal: 10m 5s\tremaining: 1m 28s\n",
      "872:\tlearn: -0.5328548\ttotal: 10m 6s\tremaining: 1m 28s\n",
      "873:\tlearn: -0.5326771\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "874:\tlearn: -0.5325549\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "875:\tlearn: -0.5324210\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "876:\tlearn: -0.5322219\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "877:\tlearn: -0.5321189\ttotal: 10m 8s\tremaining: 1m 24s\n",
      "878:\tlearn: -0.5319546\ttotal: 10m 8s\tremaining: 1m 23s\n",
      "879:\tlearn: -0.5317548\ttotal: 10m 9s\tremaining: 1m 23s\n",
      "880:\tlearn: -0.5315271\ttotal: 10m 9s\tremaining: 1m 22s\n",
      "881:\tlearn: -0.5313931\ttotal: 10m 10s\tremaining: 1m 21s\n",
      "882:\tlearn: -0.5310876\ttotal: 10m 10s\tremaining: 1m 20s\n",
      "883:\tlearn: -0.5307519\ttotal: 10m 10s\tremaining: 1m 20s\n",
      "884:\tlearn: -0.5306225\ttotal: 10m 11s\tremaining: 1m 19s\n",
      "885:\tlearn: -0.5304967\ttotal: 10m 11s\tremaining: 1m 18s\n",
      "886:\tlearn: -0.5303125\ttotal: 10m 12s\tremaining: 1m 17s\n",
      "887:\tlearn: -0.5301621\ttotal: 10m 12s\tremaining: 1m 17s\n",
      "888:\tlearn: -0.5299240\ttotal: 10m 13s\tremaining: 1m 16s\n",
      "889:\tlearn: -0.5297282\ttotal: 10m 13s\tremaining: 1m 15s\n",
      "890:\tlearn: -0.5293871\ttotal: 10m 13s\tremaining: 1m 15s\n",
      "891:\tlearn: -0.5292117\ttotal: 10m 14s\tremaining: 1m 14s\n",
      "892:\tlearn: -0.5290682\ttotal: 10m 14s\tremaining: 1m 13s\n",
      "893:\tlearn: -0.5289287\ttotal: 10m 15s\tremaining: 1m 12s\n",
      "894:\tlearn: -0.5287049\ttotal: 10m 15s\tremaining: 1m 12s\n",
      "895:\tlearn: -0.5284170\ttotal: 10m 15s\tremaining: 1m 11s\n",
      "896:\tlearn: -0.5281247\ttotal: 10m 16s\tremaining: 1m 10s\n",
      "897:\tlearn: -0.5278329\ttotal: 10m 16s\tremaining: 1m 10s\n",
      "898:\tlearn: -0.5276204\ttotal: 10m 17s\tremaining: 1m 9s\n",
      "899:\tlearn: -0.5273921\ttotal: 10m 17s\tremaining: 1m 8s\n",
      "900:\tlearn: -0.5271148\ttotal: 10m 18s\tremaining: 1m 7s\n",
      "901:\tlearn: -0.5269835\ttotal: 10m 18s\tremaining: 1m 7s\n",
      "902:\tlearn: -0.5268301\ttotal: 10m 18s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903:\tlearn: -0.5266256\ttotal: 10m 19s\tremaining: 1m 5s\n",
      "904:\tlearn: -0.5265061\ttotal: 10m 19s\tremaining: 1m 5s\n",
      "905:\tlearn: -0.5263441\ttotal: 10m 20s\tremaining: 1m 4s\n",
      "906:\tlearn: -0.5261828\ttotal: 10m 20s\tremaining: 1m 3s\n",
      "907:\tlearn: -0.5260954\ttotal: 10m 21s\tremaining: 1m 2s\n",
      "908:\tlearn: -0.5259209\ttotal: 10m 21s\tremaining: 1m 2s\n",
      "909:\tlearn: -0.5257497\ttotal: 10m 21s\tremaining: 1m 1s\n",
      "910:\tlearn: -0.5256327\ttotal: 10m 22s\tremaining: 1m\n",
      "911:\tlearn: -0.5253790\ttotal: 10m 22s\tremaining: 1m\n",
      "912:\tlearn: -0.5252187\ttotal: 10m 23s\tremaining: 59.4s\n",
      "913:\tlearn: -0.5250868\ttotal: 10m 23s\tremaining: 58.7s\n",
      "914:\tlearn: -0.5249186\ttotal: 10m 23s\tremaining: 58s\n",
      "915:\tlearn: -0.5246802\ttotal: 10m 24s\tremaining: 57.3s\n",
      "916:\tlearn: -0.5245305\ttotal: 10m 24s\tremaining: 56.6s\n",
      "917:\tlearn: -0.5242471\ttotal: 10m 25s\tremaining: 55.8s\n",
      "918:\tlearn: -0.5238605\ttotal: 10m 25s\tremaining: 55.1s\n",
      "919:\tlearn: -0.5238041\ttotal: 10m 26s\tremaining: 54.4s\n",
      "920:\tlearn: -0.5236185\ttotal: 10m 26s\tremaining: 53.7s\n",
      "921:\tlearn: -0.5235239\ttotal: 10m 26s\tremaining: 53s\n",
      "922:\tlearn: -0.5232345\ttotal: 10m 27s\tremaining: 52.3s\n",
      "923:\tlearn: -0.5229798\ttotal: 10m 27s\tremaining: 51.6s\n",
      "924:\tlearn: -0.5227052\ttotal: 10m 28s\tremaining: 50.9s\n",
      "925:\tlearn: -0.5226236\ttotal: 10m 28s\tremaining: 50.2s\n",
      "926:\tlearn: -0.5223138\ttotal: 10m 28s\tremaining: 49.5s\n",
      "927:\tlearn: -0.5220955\ttotal: 10m 29s\tremaining: 48.8s\n",
      "928:\tlearn: -0.5219686\ttotal: 10m 29s\tremaining: 48.1s\n",
      "929:\tlearn: -0.5216462\ttotal: 10m 30s\tremaining: 47.4s\n",
      "930:\tlearn: -0.5213069\ttotal: 10m 30s\tremaining: 46.7s\n",
      "931:\tlearn: -0.5211464\ttotal: 10m 31s\tremaining: 46s\n",
      "932:\tlearn: -0.5208796\ttotal: 10m 31s\tremaining: 45.3s\n",
      "933:\tlearn: -0.5205898\ttotal: 10m 31s\tremaining: 44.7s\n",
      "934:\tlearn: -0.5203626\ttotal: 10m 32s\tremaining: 44s\n",
      "935:\tlearn: -0.5201606\ttotal: 10m 32s\tremaining: 43.3s\n",
      "936:\tlearn: -0.5200423\ttotal: 10m 33s\tremaining: 42.6s\n",
      "937:\tlearn: -0.5198095\ttotal: 10m 33s\tremaining: 41.9s\n",
      "938:\tlearn: -0.5195525\ttotal: 10m 34s\tremaining: 41.2s\n",
      "939:\tlearn: -0.5192857\ttotal: 10m 34s\tremaining: 40.5s\n",
      "940:\tlearn: -0.5191020\ttotal: 10m 34s\tremaining: 39.8s\n",
      "941:\tlearn: -0.5187544\ttotal: 10m 35s\tremaining: 39.1s\n",
      "942:\tlearn: -0.5184667\ttotal: 10m 35s\tremaining: 38.4s\n",
      "943:\tlearn: -0.5183638\ttotal: 10m 36s\tremaining: 37.7s\n",
      "944:\tlearn: -0.5181669\ttotal: 10m 36s\tremaining: 37.1s\n",
      "945:\tlearn: -0.5179978\ttotal: 10m 37s\tremaining: 36.4s\n",
      "946:\tlearn: -0.5178558\ttotal: 10m 37s\tremaining: 35.7s\n",
      "947:\tlearn: -0.5177080\ttotal: 10m 37s\tremaining: 35s\n",
      "948:\tlearn: -0.5175786\ttotal: 10m 38s\tremaining: 34.3s\n",
      "949:\tlearn: -0.5174337\ttotal: 10m 38s\tremaining: 33.6s\n",
      "950:\tlearn: -0.5172461\ttotal: 10m 39s\tremaining: 32.9s\n",
      "951:\tlearn: -0.5171741\ttotal: 10m 39s\tremaining: 32.2s\n",
      "952:\tlearn: -0.5169229\ttotal: 10m 39s\tremaining: 31.6s\n",
      "953:\tlearn: -0.5166655\ttotal: 10m 40s\tremaining: 30.9s\n",
      "954:\tlearn: -0.5163901\ttotal: 10m 40s\tremaining: 30.2s\n",
      "955:\tlearn: -0.5161566\ttotal: 10m 41s\tremaining: 29.5s\n",
      "956:\tlearn: -0.5159637\ttotal: 10m 41s\tremaining: 28.8s\n",
      "957:\tlearn: -0.5158372\ttotal: 10m 42s\tremaining: 28.1s\n",
      "958:\tlearn: -0.5156369\ttotal: 10m 42s\tremaining: 27.5s\n",
      "959:\tlearn: -0.5154364\ttotal: 10m 42s\tremaining: 26.8s\n",
      "960:\tlearn: -0.5151363\ttotal: 10m 43s\tremaining: 26.1s\n",
      "961:\tlearn: -0.5149510\ttotal: 10m 43s\tremaining: 25.4s\n",
      "962:\tlearn: -0.5147357\ttotal: 10m 44s\tremaining: 24.7s\n",
      "963:\tlearn: -0.5145140\ttotal: 10m 44s\tremaining: 24.1s\n",
      "964:\tlearn: -0.5143323\ttotal: 10m 44s\tremaining: 23.4s\n",
      "965:\tlearn: -0.5141087\ttotal: 10m 45s\tremaining: 22.7s\n",
      "966:\tlearn: -0.5139979\ttotal: 10m 45s\tremaining: 22s\n",
      "967:\tlearn: -0.5138725\ttotal: 10m 46s\tremaining: 21.4s\n",
      "968:\tlearn: -0.5136182\ttotal: 10m 46s\tremaining: 20.7s\n",
      "969:\tlearn: -0.5134372\ttotal: 10m 47s\tremaining: 20s\n",
      "970:\tlearn: -0.5131862\ttotal: 10m 47s\tremaining: 19.3s\n",
      "971:\tlearn: -0.5131057\ttotal: 10m 47s\tremaining: 18.7s\n",
      "972:\tlearn: -0.5128840\ttotal: 10m 48s\tremaining: 18s\n",
      "973:\tlearn: -0.5127967\ttotal: 10m 48s\tremaining: 17.3s\n",
      "974:\tlearn: -0.5126796\ttotal: 10m 49s\tremaining: 16.6s\n",
      "975:\tlearn: -0.5125770\ttotal: 10m 49s\tremaining: 16s\n",
      "976:\tlearn: -0.5123677\ttotal: 10m 49s\tremaining: 15.3s\n",
      "977:\tlearn: -0.5120589\ttotal: 10m 50s\tremaining: 14.6s\n",
      "978:\tlearn: -0.5117674\ttotal: 10m 50s\tremaining: 14s\n",
      "979:\tlearn: -0.5115541\ttotal: 10m 51s\tremaining: 13.3s\n",
      "980:\tlearn: -0.5113985\ttotal: 10m 51s\tremaining: 12.6s\n",
      "981:\tlearn: -0.5113457\ttotal: 10m 52s\tremaining: 12s\n",
      "982:\tlearn: -0.5110756\ttotal: 10m 52s\tremaining: 11.3s\n",
      "983:\tlearn: -0.5108435\ttotal: 10m 52s\tremaining: 10.6s\n",
      "984:\tlearn: -0.5106593\ttotal: 10m 53s\tremaining: 9.95s\n",
      "985:\tlearn: -0.5104571\ttotal: 10m 53s\tremaining: 9.28s\n",
      "986:\tlearn: -0.5101786\ttotal: 10m 54s\tremaining: 8.62s\n",
      "987:\tlearn: -0.5100210\ttotal: 10m 54s\tremaining: 7.95s\n",
      "988:\tlearn: -0.5098391\ttotal: 10m 54s\tremaining: 7.28s\n",
      "989:\tlearn: -0.5094545\ttotal: 10m 55s\tremaining: 6.62s\n",
      "990:\tlearn: -0.5091443\ttotal: 10m 55s\tremaining: 5.96s\n",
      "991:\tlearn: -0.5090038\ttotal: 10m 56s\tremaining: 5.29s\n",
      "992:\tlearn: -0.5088798\ttotal: 10m 56s\tremaining: 4.63s\n",
      "993:\tlearn: -0.5087933\ttotal: 10m 57s\tremaining: 3.97s\n",
      "994:\tlearn: -0.5085562\ttotal: 10m 57s\tremaining: 3.3s\n",
      "995:\tlearn: -0.5084439\ttotal: 10m 57s\tremaining: 2.64s\n",
      "996:\tlearn: -0.5082302\ttotal: 10m 58s\tremaining: 1.98s\n",
      "997:\tlearn: -0.5081614\ttotal: 10m 58s\tremaining: 1.32s\n",
      "998:\tlearn: -0.5079348\ttotal: 10m 59s\tremaining: 660ms\n",
      "999:\tlearn: -0.5076031\ttotal: 10m 59s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7266414141414141"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cb=CatBoostClassifier()\n",
    "cb.fit(x_train,y_train)\n",
    "pred8=cb.predict(x_test)\n",
    "accuracy_score(y_test,pred8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Operation with Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On fingolimod and have been since December 201...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  drug\n",
       "0  256 (previously stable on natalizumab), with 5...    33\n",
       "1  On fingolimod and have been since December 201...    33\n",
       "2  Apparently it's shingles! :-/ I do have a few ...    39\n",
       "3  If the Docetaxel doing once a week x3 weeks th...    81\n",
       "4  CC, Stelara worked in a matter of days for me....    78"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"\test_tOlRoBf.csv\")\n",
    "test_data2=pd.read_csv(\"\test_tOlRoBf.csv\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label=LabelEncoder()\n",
    "#test_data[\"unique_hash\"]=label.fit_transform(test_data[\"unique_hash\"])\n",
    "test_data[\"drug\"]=label.fit_transform(test_data[\"drug\"])\n",
    "test_data.drop(\"unique_hash\",axis=1,inplace=True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=test_data[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfvec_test=TfidfVectorizer(min_df=3, max_features=1000,strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(1, 4), use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "transvec_test=tfvec_test.fit_transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3695, 51)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsvd_test=TruncatedSVD(n_components=50)\n",
    "test_data_text=tsvd_test.fit_transform(transvec_test)\n",
    "test_new_data=pd.DataFrame(test_data_text,columns=[\"n\"+str(i) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>...</th>\n",
       "      <th>n40</th>\n",
       "      <th>n41</th>\n",
       "      <th>n42</th>\n",
       "      <th>n43</th>\n",
       "      <th>n44</th>\n",
       "      <th>n45</th>\n",
       "      <th>n46</th>\n",
       "      <th>n47</th>\n",
       "      <th>n48</th>\n",
       "      <th>n49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>0.024212</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>-0.031532</td>\n",
       "      <td>-0.055755</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>0.134186</td>\n",
       "      <td>0.052732</td>\n",
       "      <td>0.041644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130018</td>\n",
       "      <td>0.149075</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>0.034003</td>\n",
       "      <td>0.039727</td>\n",
       "      <td>0.064267</td>\n",
       "      <td>0.099432</td>\n",
       "      <td>-0.111729</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>-0.049151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>0.124385</td>\n",
       "      <td>-0.046962</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-0.062577</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177769</td>\n",
       "      <td>0.032538</td>\n",
       "      <td>-0.096181</td>\n",
       "      <td>-0.043586</td>\n",
       "      <td>-0.022599</td>\n",
       "      <td>-0.088677</td>\n",
       "      <td>0.096256</td>\n",
       "      <td>-0.026726</td>\n",
       "      <td>0.001448</td>\n",
       "      <td>-0.037403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   drug        n0        n1        n2        n3        n4        n5        n6  \\\n",
       "0    33  0.053811  0.024212 -0.033774 -0.031532 -0.055755 -0.002924  0.134186   \n",
       "1    33  0.124385 -0.046962 -0.005413 -0.062577 -0.008021  0.029231  0.018559   \n",
       "\n",
       "         n7        n8    ...          n40       n41       n42       n43  \\\n",
       "0  0.052732  0.041644    ...     0.130018  0.149075 -0.008368  0.034003   \n",
       "1  0.007530 -0.005441    ...     0.177769  0.032538 -0.096181 -0.043586   \n",
       "\n",
       "        n44       n45       n46       n47       n48       n49  \n",
       "0  0.039727  0.064267  0.099432 -0.111729 -0.011905 -0.049151  \n",
       "1 -0.022599 -0.088677  0.096256 -0.026726  0.001448 -0.037403  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mod=pd.concat([test_data,test_new_data],axis=1)\n",
    "test_mod.drop(\"text\",axis=1,inplace=True)\n",
    "test_mod.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2924, 51)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "test_mod=sc.fit_transform(test_mod)\n",
    "test_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2924, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_hash</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                unique_hash  sentiment\n",
       "0  9e9a8166b84114aca147bf409f6f956635034c08          2\n",
       "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a          2\n",
       "2  50b6d851bcff4f35afe354937949e9948975adf7          2\n",
       "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          2\n",
       "4  8b37d169dee5bdae27060949242fb54feb6a7f7f          2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_mod.shape)\n",
    "test_pred=sv.predict(test_mod)\n",
    "submission=pd.DataFrame(test_pred)\n",
    "#submission.insert(0,'unique_hash',test_data[\"unique_hash\"])\n",
    "submission.columns=[\"sentiment\"]\n",
    "submission.insert(0,'unique_hash',test_data2['unique_hash'])\n",
    "submission=submission.round(0)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"sample_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2924\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['sentiment'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
